# logs-to-kafka.conf
input {
  beats {
    port => 5045
  }
}

filter {
  # Filebeat가 전달한 병합된 JSON 문자열을 파싱합니다.
  json {
    source => "message"
    remove_field => ["message"]
  }

  # JSON 파싱 실패 시 이벤트 삭제
  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  # timestamp 필드 변환
  if [timestamp] {
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "timestamp"
    }
  }

  # 불필요한 메타데이터 제거
  mutate {
    remove_field => ["@version", "@timestamp", "agent", "cloud", "ecs", "input", "log", "tags"]
  }

  # 조건에 따른 로그 필터링
  if [request] =~ "/.env.testing" {
    drop { }
  }
  
  if ([request] == "GET / HTTP/1.1") and ([http_user_agent] !~ /python-requests\/2\.25\.1/) {
    drop { }
  }
}

output {
  if "${ENABLE_KAFKA_OUTPUT}" == "true" {
    kafka {
      bootstrap_servers => "${LOGSTASH_KAFKA_ENDPOINT}"
      topic_id => "nginx-topic"
      codec => json
    }
  } else {
    stdout {
      codec => rubydebug
    }
  }
}

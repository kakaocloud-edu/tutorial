# Logstash 설정 파일 - Filebeat에서 받은 로그를 JSON 파싱 후 Kafka로 전송

input {
  beats {
    port => 5045  # Filebeat가 로그를 전송할 포트
  }
}

filter {
  # Filebeat가 전달한 병합된 JSON 문자열을 파싱
  json {
    source => "message"
    remove_field => ["message"]
  }

  # JSON 파싱 실패한 경우 제거
  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  # 'timestamp' 필드를 ISO 8601 형식으로 변환 (Hive TIMESTAMP와 호환)
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "timestamp"
    }
  }

  # 숫자형 필드들을 실제 수치로 변환 → Hive에서 INT/DOUBLE로 인식 가능
  mutate {
    convert => {
      "status" => "integer"
      "body_bytes_sent" => "integer"
      "request_time" => "float"
      "upstream_response_time" => "float"
    }
  }

  # 불필요한 메타데이터 필드 제거
  mutate {
    remove_field => [
      "@version", "@timestamp", "agent", "cloud", "ecs", "input", "log", "tags"
    ]
  }
}

output {
  # ENABLE_KAFKA_OUTPUT=true 일 때 Kafka로 전송
  if "${ENABLE_KAFKA_OUTPUT}" == "true" {
    kafka {
      bootstrap_servers => "${LOGSTASH_KAFKA_ENDPOINT}"
      topic_id => "nginx-topic"
      codec => json
    }
  } else {
    stdout {
      codec => rubydebug
    }
  }
}

# logs-to-kafka.conf
input {
  beats {
    port => 5045
  }
}

filter {
  # Filebeat가 전달한 병합된 JSON 문자열을 파싱합니다.
  json {
    source => "message"
    remove_field => ["message"]
  }

  # JSON 파싱 실패 시 이벤트 삭제
  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  # timestamp 필드 변환
  if [timestamp] {
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "timestamp"
    }
  }

  # 불필요한 메타데이터 제거
  mutate {
    remove_field => ["@version", "@timestamp", "agent", "cloud", "ecs", "input", "log", "tags"]
  }

  # 허용되지 않은 엔드포인트는 drop 처리
  if [request] !~ /(POST \/add_user|GET \/categories|GET \/products|POST \/login|POST \/cart\/add|POST \/delete_user|GET \/error)/ {
    drop { }
  }
}

output {
  if "${ENABLE_KAFKA_OUTPUT}" == "true" {
    kafka {
      bootstrap_servers => "${LOGSTASH_KAFKA_ENDPOINT}"
      topic_id => "nginx-topic"
      codec => json
    }
  } else {
    stdout {
      codec => rubydebug
    }
  }
}

# /etc/logstash/conf.d/logs-to-kafka.conf
input {
  beats {
    port => 5045
  }
}

filter {
  # Filebeat가 전달한 병합된 JSON 문자열을 파싱합니다.
  json {
    source => "message"
    remove_field => ["message"]
  }

  # JSON 파싱 실패 시 이벤트 삭제
  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  # "timestamp" 필드를 변환하여 원래 필드 이름을 유지합니다.
  if [timestamp] {
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "timestamp"
    }
  }

  # 불필요한 메타데이터 필드 제거
  mutate {
    remove_field => ["@version", "@timestamp", "agent", "cloud", "ecs", "input", "log", "tags"]
  }

  # HTTP 요청인지 확인: GET 또는 POST로 시작하지 않으면 drop
  if [request] !~ /^(GET|POST) / {
    drop { }
  }

  # 허용된 엔드포인트만 통과시키도록 정규표현식으로 필터링
  # HTTP 버전은 1.0 또는 1.1 모두 허용
  if [request] !~ /^(POST \/add_user HTTP\/1\.[01]|GET \/categories HTTP\/1\.[01]|GET \/products HTTP\/1\.[01]|POST \/login HTTP\/1\.[01]|POST \/cart\/add HTTP\/1\.[01]|POST \/delete_user HTTP\/1\.[01]|GET \/error HTTP\/1\.[01])$/ {
    drop { }
  }
}

output {
  if "${ENABLE_KAFKA_OUTPUT}" == "true" {
    kafka {
      bootstrap_servers => "${LOGSTASH_KAFKA_ENDPOINT}"
      topic_id => "nginx-topic"
      codec => json
    }
  } else {
    stdout {
      codec => rubydebug
    }
  }
}

input {
  beats {
    port => 5045
  }
}

filter {
  json {
    source => "message"
    remove_field => ["message"]
  }

  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  # 타임스탬프 처리
  if [timestamp] {
    ruby {
      code => "
        begin
          require 'time'
          timestamp_str = event.get('timestamp')
          if timestamp_str && timestamp_str != ''
            parsed_time = Time.strptime(timestamp_str, '%d/%b/%Y:%H:%M:%S %z')
            event.set('timestamp', parsed_time.strftime('%Y-%m-%d %H:%M:%S'))
          else
            event.set('timestamp', nil)
          end
        rescue => e
          event.set('timestamp', nil)
        end
      "
    }
  }

  # 필드 정리 및 null 처리
  ruby {
    code => "
      required_fields = [
        'timestamp', 'event_id', 'event_name', 'user_id', 'session_id',
        'session_index', 'is_return_visitor', 'region', 'device',
        'page_url', 'dwell_time_seconds', 'product_id', 'quantity',
        'search_term', 'review_rating', 'event_context', 'status',
        'request_time', 'http_user_agent'
      ]
      
      required_fields.each do |field|
        value = event.get(field)
        if value.nil? || value == '' || value == '-' || value == 'null'
          event.set(field, nil)
        elsif !value.is_a?(String) && !value.nil?
          event.set(field, value.to_s)
        end
      end
      
      # 불필요한 필드 완전 제거
      event.to_hash.keys.each do |key|
        unless required_fields.include?(key) || key.start_with?('@')
          event.remove(key)
        end
      end
    "
  }

  # 메타데이터 정리
  mutate {
    remove_field => [
      "@version", "agent", "cloud", "ecs", "input", "log", "tags", "host"
    ]
  }
}

output {
  kafka {
    bootstrap_servers => "10.0.3.227:9092,10.0.0.71:9092"
    topic_id => "nginx-topic-final"
    codec => avro_schema_registry {
      endpoint => "http://210.109.80.40:8081"
      schema_uri => "/etc/logstash/schema/nginx.avsc"
      subject_name => "nginx-custom-logs-allstring-value"
      register_schema => true
      check_compatibility => true
    }
    # 필수 설정
    value_serializer => "org.apache.kafka.common.serialization.ByteArraySerializer"
    # 추가 안정성 설정
    compression_type => "snappy"
    batch_size => 16384
    linger_ms => 5
    retries => 3
    retry_backoff_ms => 100
    acks => "1"
  }
}

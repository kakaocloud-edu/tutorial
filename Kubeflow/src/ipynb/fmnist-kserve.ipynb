{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f9ce70-f5b9-44f7-a8a1-506b8a7c92c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T10:08:58.985296Z",
     "iopub.status.busy": "2023-04-15T10:08:58.984964Z",
     "iopub.status.idle": "2023-04-15T10:08:58.988709Z",
     "shell.execute_reply": "2023-04-15T10:08:58.987984Z",
     "shell.execute_reply.started": "2023-04-15T10:08:58.985253Z"
    },
    "tags": []
   },
   "source": [
    "# 노트북에서 모델 학습 및 서빙 API 생성 파이프라인 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda13f19-1c7a-443b-ac17-39360e99282d",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 추가 및 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da6808-809e-4808-ace3-007b3af063fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import uuid\n",
    "from kakaocloud_kbm import KbmPipelineClient\n",
    "import kfp.compiler as compiler\n",
    "from kfp import dsl\n",
    "from kfp.dsl import ContainerOp, pipeline\n",
    "from kfp import components\n",
    "from kfp.components import create_component_from_func\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# Fashion MNIST 데이터셋 URL\n",
    "t10k_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "t10k_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "def download_and_extract(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.open(BytesIO(response.content), 'rb') as f:\n",
    "        return np.frombuffer(f.read(), np.uint8)\n",
    "\n",
    "t10k_images = download_and_extract(t10k_images_url)[16:].reshape(-1, 28, 28)\n",
    "t10k_labels = download_and_extract(t10k_labels_url)[8:]\n",
    "\n",
    "label_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "def show_images(images, labels, label_names, rows=5, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for img, ax, lbl in zip(images, axes, labels):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(label_names[lbl])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(t10k_images[:25], t10k_labels[:25], label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c86503-c723-4e75-a17c-e4429e5c9e85",
   "metadata": {},
   "source": [
    "## 2. 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e8ef6-ca73-45b2-93ee-a0fd3e6a01ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"KUBEFLOW_HOST\"] = \"{도메인주소}\"\n",
    "os.environ[\"KUBEFLOW_USERNAME\"] = \"{계정 아이디}\"\n",
    "os.environ[\"KUBEFLOW_PASSWORD\"] = \"{계정 비밀번호}\"\n",
    "\n",
    "# 환경변수들 준비\n",
    "KBM_NAMESPACE = os.environ['NB_PREFIX'].split('/')[2]\n",
    "TRAIN_PATH = 'fmnist_serve_model'\n",
    "TRAIN_CR_IMAGE = \"bigdata-150.kr-central-2.kcr.dev/kc-kubeflow/kmlp-pytorch:1.0.0.py36.cuda\"\n",
    "TASK_UUID = uuid.uuid1().hex[:8]\n",
    "PVC_NAME = f\"test-fmnist-pvc-{TASK_UUID}\"\n",
    "MODEL_NAME = f\"torch-model-{TASK_UUID}\"\n",
    "KBM_MODEL_SERV_NAME = f\"torchserve-{TASK_UUID}\"\n",
    "EPOCH_NUM = 3\n",
    "\n",
    "print(f\"Namespace : {KBM_NAMESPACE}\")\n",
    "print(f\"Train Path : {TRAIN_PATH}\")\n",
    "print(f\"Image for Training : {TRAIN_CR_IMAGE}\")\n",
    "print(f\"Model Name : {MODEL_NAME}\")\n",
    "print(f\"Model PVC Name : {PVC_NAME}\")\n",
    "print(f\"Model Server Name : {KBM_MODEL_SERV_NAME}\")\n",
    "print(f\"Number of Epochs : {EPOCH_NUM}\")\n",
    "\n",
    "# 학습을 위한 폴더 생성\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4fc1be-4c50-4e87-93af-a5e35a71ce73",
   "metadata": {},
   "source": [
    "## 3. 파이프라인 컴포넌트 빌드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc77d5b-8570-4b7d-9682-39e07dcc7f9d",
   "metadata": {},
   "source": [
    "### 3-1. Fashion MNIST 데이터셋을 다운로드하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66cfe7-525c-4144-a1f9-6ef41f992b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_fashion_mnist(\n",
    "    t10k_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz',\n",
    "    t10k_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
    "    train_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz',\n",
    "    train_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'\n",
    "):\n",
    "    import os\n",
    "    import requests\n",
    "    import gzip\n",
    "\n",
    "    def download_and_save(url, output_path):\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        with gzip.open(output_path, 'rb') as f_in:\n",
    "            with open(output_path.rstrip('.gz'), 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "    os.makedirs('/pvc', exist_ok=True)\n",
    "    download_and_save(t10k_images_url, '/pvc/t10k-images-idx3-ubyte.gz')\n",
    "    download_and_save(t10k_labels_url, '/pvc/t10k-labels-idx1-ubyte.gz')\n",
    "    download_and_save(train_images_url, '/pvc/train-images-idx3-ubyte.gz')\n",
    "    download_and_save(train_labels_url, '/pvc/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "    return '/pvc'\n",
    "\n",
    "dataset_op = create_component_from_func(\n",
    "    download_fashion_mnist,\n",
    "    output_component_file=f'{TRAIN_PATH}/data_component.yaml',\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['requests']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e156c-16c3-4618-a274-bd4e9314ba56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {TRAIN_PATH}/dataset_component.yaml\n",
    "name: Fashion MNIST Dataset\n",
    "description: |\n",
    "  Fashion MNIST Dataset: https://github.com/zalandoresearch/fashion-mnist\n",
    "metadata:\n",
    "  annotations:\n",
    "    author: KiC Bigdata <bigdata.platform@kakaoenterprise.com>\n",
    "inputs:\n",
    "- {name: t10k_images_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'}\n",
    "- {name: t10k_labels_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'}\n",
    "- {name: train_images_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz'}\n",
    "- {name: train_labels_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'}\n",
    "implementation:\n",
    "  container:\n",
    "    image: curlimages/curl\n",
    "    command:\n",
    "    - sh\n",
    "    - -c\n",
    "    - |\n",
    "      set -e -x -o pipefail\n",
    "      curl -L \"$0\" --output \"/pvc/t10k-images-idx3-ubyte.gz\"\n",
    "      curl -L \"$1\" --output \"/pvc/t10k-labels-idx1-ubyte.gz\"\n",
    "      curl -L \"$2\" --output \"/pvc/train-images-idx3-ubyte.gz\"\n",
    "      curl -L \"$3\" --output \"/pvc/train-labels-idx1-ubyte.gz\"\n",
    "      if [ -s /pvc/t10k-images-idx3-ubyte.gz ] && [ -s /pvc/t10k-labels-idx1-ubyte.gz ] && [ -s /pvc/train-images-idx3-ubyte.gz ] && [ -s /pvc/train-labels-idx1-ubyte.gz ]; then\n",
    "        gzip -d /pvc/t10k-images-idx3-ubyte.gz\n",
    "        gzip -d /pvc/t10k-labels-idx1-ubyte.gz\n",
    "        gzip -d /pvc/train-images-idx3-ubyte.gz\n",
    "        gzip -d /pvc/train-labels-idx1-ubyte.gz\n",
    "      else\n",
    "        echo \"Download failed, exiting.\"\n",
    "        exit 1\n",
    "      fi\n",
    "    - {inputValue: t10k_images_url}\n",
    "    - {inputValue: t10k_labels_url}\n",
    "    - {inputValue: train_images_url}\n",
    "    - {inputValue: train_labels_url}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2042056-eeb1-49ef-a176-53fae491f973",
   "metadata": {},
   "source": [
    "### 3-2. Fashion MNIST 모델 학습 및 서빙 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae22e3-9e21-487a-a1d7-b7a012b5446a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fmnist(\n",
    "    epoch_num: str,\n",
    "    model_name: str,\n",
    "    train_images_path: str,\n",
    "    train_labels_path: str,\n",
    "    test_images_path: str,\n",
    "    test_labels_path: str\n",
    "):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torchvision import transforms\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from PIL import Image\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    class FashionMNISTDataset(Dataset):\n",
    "        def __init__(self, images_path, labels_path, transform=None):\n",
    "            self.images = self._read_images(images_path)\n",
    "            self.labels = self._read_labels(labels_path)\n",
    "            self.transform = transform\n",
    "\n",
    "        def _read_images(self, path):\n",
    "            with open(path, 'rb') as f:\n",
    "                images = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            images = images.reshape(-1, 28, 28, 1)  # Ensure the shape is [num_samples, 28, 28, 1]\n",
    "            return images\n",
    "\n",
    "        def _read_labels(self, path):\n",
    "            with open(path, 'rb') as f:\n",
    "                labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            return labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            image = Image.fromarray(image.squeeze(), mode='L')  # Convert to PIL Image\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, torch.tensor(label, dtype=torch.long)  # Convert label to LongTensor\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 7 * 7)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    train_dataset = FashionMNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "    test_dataset = FashionMNISTDataset(test_images_path, test_labels_path, transform=transform)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Model Training\n",
    "    model = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(int(epoch_num)):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    \n",
    "                print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    os.makedirs('/pvc/fmnist_model', exist_ok=True)\n",
    "    torch.save(model.state_dict(), '/pvc/fmnist_model/fmnist_cnn.pth')\n",
    "\n",
    "    # Save handler.py\n",
    "    handler_code = \"\"\"\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import logging\n",
    "import base64\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('mylog - %(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "class ImageClassifierHandler(BaseHandler):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, context):\n",
    "        import torch.nn as nn  # add import here\n",
    "        logger.info(\"Initializing handler...\")\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Net, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "                self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "                self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "                self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(torch.relu(self.conv1(x)))\n",
    "                x = self.pool(torch.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 64 * 7 * 7)\n",
    "                x = torch.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "\n",
    "        self.manifest = context.manifest\n",
    "        properties = context.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model_path = model_dir + '/fmnist_cnn.pth'\n",
    "        logger.info(f\"Loading model from {model_path}\")\n",
    "        try:\n",
    "            self.model = Net()\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            logger.info(\"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "\n",
    "        self.image_processing = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        self.initialized = True\n",
    "        logger.info(\"Handler initialized successfully.\")\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        logger.info(\"Preprocessing input data...\")\n",
    "        try:\n",
    "            image = data[0].get(\"data\") or data[0].get(\"body\")\n",
    "            if isinstance(image, str):\n",
    "                image = io.BytesIO(base64.b64decode(image))\n",
    "            else:\n",
    "                image = io.BytesIO(image)\n",
    "            image = Image.open(image)\n",
    "            image = self.image_processing(image)\n",
    "            logger.info(\"Preprocessing completed.\")\n",
    "            return image.unsqueeze(0).to(self.device)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in preprocessing: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def inference(self, img):\n",
    "        logger.info(\"Running inference...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output = self.model(img)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "            logger.info(f\"Inference completed. Prediction: {predicted.item()}\")\n",
    "            return predicted\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in inference: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        logger.info(\"Postprocessing inference output...\")\n",
    "        try:\n",
    "            result = [int(inference_output[0])]\n",
    "            logger.info(f\"Postprocessing completed. Result: {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in postprocessing: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def handle(self, data, context):\n",
    "        logger.info(\"Handling request...\")\n",
    "        try:\n",
    "            if not self.initialized:\n",
    "                self.initialize(context)\n",
    "            data = self.preprocess(data)\n",
    "            data = self.inference(data)\n",
    "            data = self.postprocess(data)\n",
    "            logger.info(\"Request handled successfully.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in handle: {e}\")\n",
    "            raise e\n",
    "\"\"\"\n",
    "\n",
    "    with open(\"/pvc/fmnist_model/handler.py\", \"w\") as f:\n",
    "        f.write(handler_code)\n",
    "        \n",
    "    \n",
    "    # config for torchserve\n",
    "    import json\n",
    "    config = dict(\n",
    "        inference_address=\"http://0.0.0.0:8085\",\n",
    "        management_address=\"http://0.0.0.0:8085\",\n",
    "        metrics_address=\"http://0.0.0.0:8082\",\n",
    "        grpc_inference_port=7070,\n",
    "        grpc_management_port=7071,\n",
    "        enable_envvars_config=\"true\",\n",
    "        install_py_dep_per_model=\"true\",\n",
    "        model_store=\"/mnt/pvc/fmnist_model/model-store\",\n",
    "        model_snapshot=json.dumps({\n",
    "            \"name\": \"startup.cfg\",\n",
    "            \"modelCount\": 1,\n",
    "            \"models\": {\n",
    "                f\"{model_name}\": {  # Model Name\n",
    "                    \"1.0\": {\n",
    "                        \"defaultVersion\": \"true\",\n",
    "                        \"marName\": f\"{model_name}.mar\",\n",
    "                        \"minWorkers\": 1,\n",
    "                        \"maxWorkers\": 5,\n",
    "                        \"batchSize\": 1,\n",
    "                        \"maxBatchDelay\": 10,\n",
    "                        \"responseTimeout\": 60,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }),\n",
    "    )\n",
    "    # creating config & config folder\n",
    "    if not os.path.exists(\"/pvc/fmnist_model/config\"):\n",
    "        os.mkdir(\"/pvc/fmnist_model/config\")\n",
    "        \n",
    "    with open(\"/pvc/fmnist_model/config/config.properties\", \"w\") as f:\n",
    "        for i, j in config.items():\n",
    "            f.write(f\"{i}={j}\\n\")\n",
    "            \n",
    "train_fmnist_op = components.create_component_from_func(\n",
    "    train_fmnist, \n",
    "    output_component_file=f'{TRAIN_PATH}/train_component.yaml',\n",
    "    base_image=TRAIN_CR_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bbc0f-bead-4b6f-b7ab-f29a3c6ef3be",
   "metadata": {},
   "source": [
    "### 3-3. 서빙을 위한 MAR 파일 생성 컴포넌트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43082c-e400-45f8-9021-e733d27ad623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_marfile():\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"Creating Marfile\",\n",
    "        command=[\"/bin/sh\"],\n",
    "        image=\"python:3.9\",\n",
    "        arguments=[\n",
    "            \"-c\",\n",
    "            f\"cd /pvc/fmnist_model; pip install torchserve torch-model-archiver torch-workflow-archiver; torch-model-archiver --model-name {MODEL_NAME} --version 1.0 --serialized-file fmnist_cnn.pth --handler handler.py --force; mkdir model-store; mv -f {MODEL_NAME}.mar model-store\"\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c464786-81ad-48e9-ac1d-d2b22f49f0d6",
   "metadata": {},
   "source": [
    "### 3-4. KServe 컴포넌트 YAML 파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308d40-be20-4788-b500-5bd0b176c1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {TRAIN_PATH}/kserve_component.yaml\n",
    "name: Serve a model with KServe \n",
    "description: Serve Models using KServe \n",
    "inputs:\n",
    "  - {name: Action,                    type: String, default: 'create',     description: 'Action to execute on KServe'}\n",
    "  - {name: Model Name,                type: String, default: '',           description: 'Name to give to the deployed model'}\n",
    "  - {name: Model URI,                 type: String, default: '',           description: 'Path of the S3 or GCS compatible directory containing the model.'}\n",
    "  - {name: Canary Traffic Percent,    type: String, default: '100',        description: 'The traffic split percentage between the candidate model and the last ready model'}\n",
    "  - {name: Namespace,                 type: String, default: '',           description: 'Kubernetes namespace where the KServe service is deployed.'}\n",
    "  - {name: Framework,                 type: String, default: '',           description: 'Machine Learning Framework for Model Serving.'}\n",
    "  - {name: Custom Model Spec,         type: String, default: '{}',         description: 'Custom model runtime container spec in JSON'}\n",
    "  - {name: Autoscaling Target,        type: String, default: '0',          description: 'Autoscaling Target Number'}\n",
    "  - {name: Service Account,           type: String, default: '',           description: 'ServiceAccount to use to run the InferenceService pod'}\n",
    "  - {name: Enable Istio Sidecar,      type: Bool,   default: 'True',       description: 'Whether to enable istio sidecar injection'}\n",
    "  - {name: InferenceService YAML,     type: String, default: '{}',         description: 'Raw InferenceService serialized YAML for deployment'}\n",
    "  - {name: Watch Timeout,             type: String, default: '300',        description: \"Timeout seconds for watching until InferenceService becomes ready.\"}\n",
    "  - {name: Min Replicas,              type: String, default: '-1',         description: 'Minimum number of InferenceService replicas'}\n",
    "  - {name: Max Replicas,              type: String, default: '-1',         description: 'Maximum number of InferenceService replicas'}\n",
    "  - {name: Request Timeout,           type: String, default: '60',         description: \"Specifies the number of seconds to wait before timing out a request to the component.\"}\n",
    "  - {name: Enable ISVC Status,        type: Bool,   default: 'True',       description: \"Specifies whether to store the inference service status as the output parameter\"}\n",
    "\n",
    "outputs:\n",
    "  - {name: InferenceService Status,   type: String,                        description: 'Status JSON output of InferenceService'}\n",
    "implementation:\n",
    "  container:\n",
    "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-component:v0.7.0.kbm.1c\n",
    "    command: ['python']\n",
    "    args: [\n",
    "      -u, kservedeployer.py,\n",
    "      --action,                 {inputValue: Action},\n",
    "      --model-name,             {inputValue: Model Name},\n",
    "      --model-uri,              {inputValue: Model URI},\n",
    "      --canary-traffic-percent, {inputValue: Canary Traffic Percent},\n",
    "      --namespace,              {inputValue: Namespace},\n",
    "      --framework,              {inputValue: Framework},\n",
    "      --custom-model-spec,      {inputValue: Custom Model Spec},\n",
    "      --autoscaling-target,     {inputValue: Autoscaling Target},\n",
    "      --service-account,        {inputValue: Service Account},\n",
    "      --enable-istio-sidecar,   {inputValue: Enable Istio Sidecar},\n",
    "      --output-path,            {outputPath: InferenceService Status},\n",
    "      --inferenceservice-yaml,  {inputValue: InferenceService YAML},\n",
    "      --watch-timeout,          {inputValue: Watch Timeout},\n",
    "      --min-replicas,           {inputValue: Min Replicas},\n",
    "      --max-replicas,           {inputValue: Max Replicas},\n",
    "      --request-timeout,        {inputValue: Request Timeout},\n",
    "      --enable-isvc-status,     {inputValue: Enable ISVC Status}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c9a76-df2a-4b42-a99e-be69933bd760",
   "metadata": {},
   "source": [
    "### 3-5. KServe 인퍼런스 모델 생성 컴포넌트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982dcbfa-1c5a-4265-ae21-422c4c0eb31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.components import load_component_from_file\n",
    "\n",
    "def create_inference_model():\n",
    "    kserve_op = load_component_from_file(f'{TRAIN_PATH}/kserve_component.yaml')\n",
    "    \n",
    "    model_name = KBM_MODEL_SERV_NAME\n",
    "    namespace = KBM_NAMESPACE\n",
    "    model_uri = f\"pvc://{PVC_NAME}/fmnist_model\"\n",
    "    framework=\"pytorch\"\n",
    "    \n",
    "    opt = kserve_op(action=\"apply\",\n",
    "              model_name=model_name,\n",
    "              model_uri=model_uri,\n",
    "              namespace=namespace,\n",
    "              framework=framework)\n",
    "    \n",
    "    opt.set_cpu_limit(cpu=\"2\").set_memory_limit(memory=\"4G\")\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45f4bc-c22a-4e60-b580-2ed86f34fd1d",
   "metadata": {},
   "source": [
    "## 4. 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7febc1-7fe5-4472-b876-e1a36cf80622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Fashion MNIST Model Pipeline\"\n",
    ")\n",
    "def fmnist_model_pipeline(\n",
    "    t10k_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz',\n",
    "    t10k_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
    "    train_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz',\n",
    "    train_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz',\n",
    "    model_name: str = \"torch-model\",\n",
    "    epoch_num: str = \"4\"\n",
    "):\n",
    "    \n",
    "    vop = dsl.VolumeOp(\n",
    "        name=\"volume_creation\",\n",
    "        resource_name=PVC_NAME,\n",
    "        generate_unique_name=False,\n",
    "        size=\"10Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "    \n",
    "    download_data = dataset_op(\n",
    "        t10k_images_url=t10k_images_url,\n",
    "        t10k_labels_url=t10k_labels_url,\n",
    "        train_images_url=train_images_url,\n",
    "        train_labels_url=train_labels_url\n",
    "    ).add_pvolumes({\"/pvc\": vop.volume})\n",
    "    download_data.set_cpu_limit(cpu=\"1\").set_memory_limit(memory=\"2G\")\n",
    "\n",
    "    model_train = train_fmnist_op(\n",
    "        epoch_num,\n",
    "        model_name,\n",
    "        '/pvc/train-images-idx3-ubyte',\n",
    "        '/pvc/train-labels-idx1-ubyte',\n",
    "        '/pvc/t10k-images-idx3-ubyte',\n",
    "        '/pvc/t10k-labels-idx1-ubyte'\n",
    "    ).add_node_selector_constraint(\n",
    "        'nvidia.com/gpu.present', 'true' # GPU 사용 활성화\n",
    "    ).add_pvolumes({\"/pvc\": vop.volume})\n",
    "    \n",
    "    model_train.add_resource_limit(\n",
    "        \"nvidia.com/mig-1g.10gb\", \"1\"\n",
    "    )\n",
    "    model_train.set_cpu_limit(cpu=\"4\").set_memory_limit(memory=\"8G\")\n",
    "    model_train.set_display_name(\"Training Fashion MNIST Model\")\n",
    "    model_train.after(download_data)\n",
    "    \n",
    "    marfile = create_marfile()\n",
    "    marfile.add_pvolumes({\"/pvc\": vop.volume})\n",
    "    marfile.set_display_name(\"Creating Marfile\")\n",
    "    marfile.execution_options.caching_strategy.max_cache_staleness = \"P0D\" # cache 사용않는 옵션\n",
    "    marfile.set_cpu_limit(cpu=\"1\").set_memory_limit(memory=\"2G\")\n",
    "    marfile.after(model_train)\n",
    "\n",
    "    inference_model = create_inference_model()\n",
    "    inference_model.add_pvolumes({\"/pvc\": vop.volume})\n",
    "    inference_model.set_cpu_limit(cpu=\"4\").set_memory_limit(memory=\"8G\")\n",
    "    inference_model.after(marfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35aa31-2d06-478f-af69-5de5da953374",
   "metadata": {},
   "source": [
    "## 5. 파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e991c3-aa62-458a-b1c1-70232f518bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = fmnist_model_pipeline.__name__ + ' test experiment'\n",
    "run_name = fmnist_model_pipeline.__name__ + ' run'\n",
    "\n",
    "print(\"experiment_name: \" + experiment_name)\n",
    "print(\"run_name: \" + run_name)\n",
    "\n",
    "arguments = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"epoch_num\": str(EPOCH_NUM)\n",
    "}\n",
    "\n",
    "client = KbmPipelineClient()\n",
    "client.create_run_from_pipeline_func(\n",
    "    fmnist_model_pipeline, \n",
    "    experiment_name=experiment_name, \n",
    "    run_name=run_name, \n",
    "    arguments=arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b045a9e-62c0-43e8-80ce-c27e7075d031",
   "metadata": {},
   "source": [
    "## 6. 모델 서빙 API 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c5c1f-fbb1-4947-8e36-770b5f7aa68a",
   "metadata": {},
   "source": [
    "### 6-1. 모델 서빙 API 테스트 이미지 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d96abd-cd35-4312-8420-847843dfa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# Fashion MNIST 데이터셋 URL\n",
    "t10k_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "t10k_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# 데이터 다운로드 및 압축 해제 함수\n",
    "def download_and_extract(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.open(BytesIO(response.content), 'rb') as f:\n",
    "        return np.frombuffer(f.read(), np.uint8)\n",
    "\n",
    "# 데이터 다운로드 및 로드\n",
    "t10k_images = download_and_extract(t10k_images_url)[16:].reshape(-1, 28, 28)\n",
    "t10k_labels = download_and_extract(t10k_labels_url)[8:]\n",
    "\n",
    "# 라벨 이름 정의\n",
    "label_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "# 랜덤 이미지 선택 및 출력 함수\n",
    "def get_random_image(images, labels):\n",
    "    random_idx = np.random.randint(len(images))\n",
    "    random_image = images[random_idx]\n",
    "    random_label = labels[random_idx]\n",
    "    return random_image, random_label\n",
    "\n",
    "def show_image(image, label, label_names):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Label: {label} ({label_names[label]})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 랜덤 이미지 선택\n",
    "random_image, random_label = get_random_image(t10k_images, t10k_labels)\n",
    "\n",
    "# 랜덤 이미지 출력\n",
    "show_image(random_image, random_label, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ddfbb-8d9e-4fc1-aa02-bcd84a8af13d",
   "metadata": {},
   "source": [
    "### 6-2. 모델 서빙 API 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0fbbd-9df7-41f2-b109-16de95ac27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 설정 변수\n",
    "KBM_NAMESPACE = os.environ['NB_PREFIX'].split('/')[2]\n",
    "KUBEFLOW_HOST = os.environ[\"KUBEFLOW_HOST\"]\n",
    "KUBEFLOW_USERNAME = os.environ[\"KUBEFLOW_USERNAME\"]\n",
    "KUBEFLOW_PASSWORD = os.environ[\"KUBEFLOW_PASSWORD\"]\n",
    "MODEL_NAME = f\"torch-model-{TASK_UUID}\"\n",
    "KBM_MODEL_SERV_NAME = f\"torchserve-{TASK_UUID}\"\n",
    "\n",
    "def get_authenticated_session():\n",
    "    session = requests.Session()\n",
    "    if KUBEFLOW_HOST.startswith(\"https\"):\n",
    "        _kargs = {\"verify\": False}\n",
    "    else:\n",
    "        _kargs = {}\n",
    "\n",
    "    response = session.get(KUBEFLOW_HOST, **_kargs)\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    session.post(response.url, headers=headers, data={\"login\": KUBEFLOW_USERNAME, \"password\": KUBEFLOW_PASSWORD})\n",
    "    session_cookie = session.cookies.get_dict()[\"authservice_session\"]\n",
    "    return session, session_cookie, _kargs\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def send_test_request(image, session, session_cookie, _kargs):\n",
    "    input_image_data = encode_image_to_base64(image)\n",
    "    data = {\"instances\": [{\"data\": input_image_data}]}\n",
    "    endpoint = f\"{KUBEFLOW_HOST}/v1/models/{MODEL_NAME}:predict\"\n",
    "    print(f\"endpoint: {endpoint}\")\n",
    "\n",
    "    response = session.post(\n",
    "        url=endpoint,\n",
    "        cookies={'authservice_session': session_cookie},\n",
    "        headers={\"Host\": f\"{KBM_MODEL_SERV_NAME}.{KBM_NAMESPACE}.{KUBEFLOW_HOST.split('/')[2]}\"},\n",
    "        json=data,\n",
    "        **_kargs\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except ValueError:\n",
    "        print(f\"Error: Unable to parse JSON response. Response text: {response.text}\")\n",
    "        return None\n",
    "    \n",
    "    return response_json\n",
    "\n",
    "session, session_cookie, _kargs = get_authenticated_session()\n",
    "\n",
    "# 사용자 이미지 로드\n",
    "#image = np.array(Image.open('dress.png'))\n",
    "#random_label = None\n",
    "\n",
    "response = send_test_request(random_image, session, session_cookie, _kargs)\n",
    "if response:\n",
    "    predicted_label = response['predictions'][0]\n",
    "    print(predicted_label)\n",
    "    if random_label is not None:\n",
    "        print(f\"입력 라벨: {label_names[random_label]}\")\n",
    "    print(f\"예측 라벨: {label_names[predicted_label]}\")\n",
    "else:\n",
    "    print(\"Failed to get prediction from the model server.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "a93d8e81-3b82-4b30-b74b-1405f7717b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "items:\n",
      "- apiVersion: serving.kserve.io/v1beta1\n",
      "  kind: InferenceService\n",
      "  metadata:\n",
      "    creationTimestamp: \"2024-06-02T16:02:06Z\"\n",
      "    finalizers:\n",
      "    - inferenceservice.finalizers\n",
      "    generation: 1\n",
      "    labels:\n",
      "      serviceEnvelope: kserve\n",
      "    name: torchserve-401a30c0\n",
      "    namespace: kbm-u-tutorial\n",
      "    resourceVersion: \"2854062\"\n",
      "    uid: a3191ce3-6586-4586-b978-29b686f3c887\n",
      "  spec:\n",
      "    predictor:\n",
      "      canaryTrafficPercent: 100\n",
      "      model:\n",
      "        modelFormat:\n",
      "          name: pytorch\n",
      "        name: \"\"\n",
      "        resources: {}\n",
      "        runtime: kserve-torchserve\n",
      "        storageUri: pvc://test-fmnist-pvc-401a30c0/fmnist_model\n",
      "      timeout: 60\n",
      "  status:\n",
      "    address:\n",
      "      url: http://torchserve-401a30c0.kbm-u-tutorial.svc.cluster.local/v2/models/torchserve-401a30c0/infer\n",
      "    components:\n",
      "      predictor:\n",
      "        address:\n",
      "          url: http://torchserve-401a30c0-predictor-default.kbm-u-tutorial.svc.cluster.local\n",
      "        latestCreatedRevision: torchserve-401a30c0-predictor-default-00001\n",
      "        latestReadyRevision: torchserve-401a30c0-predictor-default-00001\n",
      "        latestRolledoutRevision: torchserve-401a30c0-predictor-default-00001\n",
      "        traffic:\n",
      "        - latestRevision: true\n",
      "          percent: 100\n",
      "          revisionName: torchserve-401a30c0-predictor-default-00001\n",
      "        url: http://torchserve-401a30c0-predictor-default.kbm-u-tutorial.cch.co.kr\n",
      "    conditions:\n",
      "    - lastTransitionTime: \"2024-06-02T16:02:16Z\"\n",
      "      status: \"True\"\n",
      "      type: IngressReady\n",
      "    - lastTransitionTime: \"2024-06-02T16:02:16Z\"\n",
      "      severity: Info\n",
      "      status: \"True\"\n",
      "      type: PredictorConfigurationReady\n",
      "    - lastTransitionTime: \"2024-06-02T16:02:16Z\"\n",
      "      status: \"True\"\n",
      "      type: PredictorReady\n",
      "    - lastTransitionTime: \"2024-06-02T16:02:16Z\"\n",
      "      severity: Info\n",
      "      status: \"True\"\n",
      "      type: PredictorRouteReady\n",
      "    - lastTransitionTime: \"2024-06-02T16:02:16Z\"\n",
      "      status: \"True\"\n",
      "      type: Ready\n",
      "    url: http://torchserve-401a30c0.kbm-u-tutorial.cch.co.kr\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "  selfLink: \"\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n kbm-u-kubeflow-tutorial -o yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "bb4c32e4-1367-4090-b719-0bd62df49f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS      RESTARTS   AGE\n",
      "fashion-mnist-model-pipeline-7bl76-1768646895                     0/2     Completed   0          81m\n",
      "fashion-mnist-model-pipeline-7bl76-1876544998                     0/2     Completed   0          81m\n",
      "fashion-mnist-model-pipeline-7bl76-3258960250                     0/2     Completed   0          87m\n",
      "fashion-mnist-model-pipeline-7bl76-3646159569                     0/1     Completed   0          87m\n",
      "fashion-mnist-model-pipeline-7bl76-4181657997                     0/2     Completed   0          86m\n",
      "gpu-notebook-0                                                    2/2     Running     0          3d1h\n",
      "ml-pipeline-ui-artifact-575fc4bcf8-ll4cs                          2/2     Running     0          3d1h\n",
      "ml-pipeline-visualizationserver-566648874c-9vktf                  2/2     Running     0          3d1h\n",
      "torchserve-401a30c0-predictor-default-00001-deployment-6674nngx   3/3     Running     0          81m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get po -n kbm-u-kubeflow-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a4797de4-12aa-4f6a-b7fe-d7b5d12bc587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: Pod\n",
      "metadata:\n",
      "  annotations:\n",
      "    autoscaling.knative.dev/class: kpa.autoscaling.knative.dev\n",
      "    autoscaling.knative.dev/minScale: \"1\"\n",
      "    cni.projectcalico.org/containerID: 2318df9d08aebad87cee256816068d4ad853c1567ac5672fcbad9a9ee391057f\n",
      "    cni.projectcalico.org/podIP: 192.168.186.151/32\n",
      "    cni.projectcalico.org/podIPs: 192.168.186.151/32\n",
      "    internal.serving.kserve.io/storage-initializer-sourceuri: pvc://test-fmnist-pvc-401a30c0/fmnist_model\n",
      "    kubectl.kubernetes.io/default-container: kserve-container\n",
      "    kubectl.kubernetes.io/default-logs-container: kserve-container\n",
      "    prometheus.io/path: /stats/prometheus\n",
      "    prometheus.io/port: \"15020\"\n",
      "    prometheus.io/scrape: \"true\"\n",
      "    serving.knative.dev/creator: system:serviceaccount:kubeflow:kserve-controller-manager\n",
      "    sidecar.istio.io/status: '{\"initContainers\":[\"istio-init\"],\"containers\":[\"istio-proxy\"],\"volumes\":[\"workload-socket\",\"workload-certs\",\"istio-envoy\",\"istio-data\",\"istio-podinfo\",\"istio-token\",\"istiod-ca-cert\"],\"imagePullSecrets\":null,\"revision\":\"default\"}'\n",
      "  creationTimestamp: \"2024-06-02T16:02:08Z\"\n",
      "  generateName: torchserve-401a30c0-predictor-default-00001-deployment-66775f5575-\n",
      "  labels:\n",
      "    app: torchserve-401a30c0-predictor-default-00001\n",
      "    component: predictor\n",
      "    pod-template-hash: 66775f5575\n",
      "    security.istio.io/tlsMode: istio\n",
      "    service.istio.io/canonical-name: torchserve-401a30c0-predictor-default\n",
      "    service.istio.io/canonical-revision: torchserve-401a30c0-predictor-default-00001\n",
      "    serviceEnvelope: kserve\n",
      "    serving.knative.dev/configuration: torchserve-401a30c0-predictor-default\n",
      "    serving.knative.dev/configurationGeneration: \"1\"\n",
      "    serving.knative.dev/configurationUID: 4c1e6db6-541a-4ea5-a65b-9ce65e957a17\n",
      "    serving.knative.dev/revision: torchserve-401a30c0-predictor-default-00001\n",
      "    serving.knative.dev/revisionUID: b0afee6e-7698-4fa1-b196-7034cd9bd4cc\n",
      "    serving.knative.dev/service: torchserve-401a30c0-predictor-default\n",
      "    serving.knative.dev/serviceUID: 8480fb2e-37de-4896-b8d5-64d7332a4848\n",
      "    serving.kserve.io/inferenceservice: torchserve-401a30c0\n",
      "  name: torchserve-401a30c0-predictor-default-00001-deployment-6674nngx\n",
      "  namespace: kbm-u-tutorial\n",
      "  ownerReferences:\n",
      "  - apiVersion: apps/v1\n",
      "    blockOwnerDeletion: true\n",
      "    controller: true\n",
      "    kind: ReplicaSet\n",
      "    name: torchserve-401a30c0-predictor-default-00001-deployment-66775f5575\n",
      "    uid: 55a924f0-91b1-4db6-8d16-06a030ed9c8f\n",
      "  resourceVersion: \"2854010\"\n",
      "  uid: 3b584395-ba62-48d7-80e5-cd76d390cea2\n",
      "spec:\n",
      "  containers:\n",
      "  - args:\n",
      "    - torchserve\n",
      "    - --start\n",
      "    - --model-store=/mnt/models/model-store\n",
      "    - --ts-config=/mnt/models/config/config.properties\n",
      "    env:\n",
      "    - name: TS_SERVICE_ENVELOPE\n",
      "      value: kserve\n",
      "    - name: PORT\n",
      "      value: \"8080\"\n",
      "    - name: K_REVISION\n",
      "      value: torchserve-401a30c0-predictor-default-00001\n",
      "    - name: K_CONFIGURATION\n",
      "      value: torchserve-401a30c0-predictor-default\n",
      "    - name: K_SERVICE\n",
      "      value: torchserve-401a30c0-predictor-default\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-torchserve-kfs@sha256:47b23a1bac1a4b33e8fbc86cd653a372deb39503a6f54ba790a7433c9b8c6d85\n",
      "    imagePullPolicy: IfNotPresent\n",
      "    lifecycle:\n",
      "      preStop:\n",
      "        httpGet:\n",
      "          path: /wait-for-drain\n",
      "          port: 8022\n",
      "          scheme: HTTP\n",
      "    name: kserve-container\n",
      "    ports:\n",
      "    - containerPort: 8080\n",
      "      name: user-port\n",
      "      protocol: TCP\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: \"1\"\n",
      "        memory: 2Gi\n",
      "      requests:\n",
      "        cpu: \"1\"\n",
      "        memory: 2Gi\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: FallbackToLogsOnError\n",
      "    volumeMounts:\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: kube-api-access-v8s8n\n",
      "      readOnly: true\n",
      "    - mountPath: /mnt/pvc\n",
      "      name: kserve-pvc-source\n",
      "      readOnly: true\n",
      "    - mountPath: /mnt/models\n",
      "      name: kserve-provision-location\n",
      "      readOnly: true\n",
      "  - env:\n",
      "    - name: SERVING_NAMESPACE\n",
      "      value: kbm-u-tutorial\n",
      "    - name: SERVING_SERVICE\n",
      "      value: torchserve-401a30c0-predictor-default\n",
      "    - name: SERVING_CONFIGURATION\n",
      "      value: torchserve-401a30c0-predictor-default\n",
      "    - name: SERVING_REVISION\n",
      "      value: torchserve-401a30c0-predictor-default-00001\n",
      "    - name: QUEUE_SERVING_PORT\n",
      "      value: \"8012\"\n",
      "    - name: CONTAINER_CONCURRENCY\n",
      "      value: \"0\"\n",
      "    - name: REVISION_TIMEOUT_SECONDS\n",
      "      value: \"60\"\n",
      "    - name: SERVING_POD\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: metadata.name\n",
      "    - name: SERVING_POD_IP\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: status.podIP\n",
      "    - name: SERVING_LOGGING_CONFIG\n",
      "    - name: SERVING_LOGGING_LEVEL\n",
      "    - name: SERVING_REQUEST_LOG_TEMPLATE\n",
      "      value: '{\"httpRequest\": {\"requestMethod\": \"{{.Request.Method}}\", \"requestUrl\":\n",
      "        \"{{js .Request.RequestURI}}\", \"requestSize\": \"{{.Request.ContentLength}}\",\n",
      "        \"status\": {{.Response.Code}}, \"responseSize\": \"{{.Response.Size}}\", \"userAgent\":\n",
      "        \"{{js .Request.UserAgent}}\", \"remoteIp\": \"{{js .Request.RemoteAddr}}\", \"serverIp\":\n",
      "        \"{{.Revision.PodIP}}\", \"referer\": \"{{js .Request.Referer}}\", \"latency\": \"{{.Response.Latency}}s\",\n",
      "        \"protocol\": \"{{.Request.Proto}}\"}, \"traceId\": \"{{index .Request.Header \"X-B3-Traceid\"}}\"}'\n",
      "    - name: SERVING_ENABLE_REQUEST_LOG\n",
      "      value: \"false\"\n",
      "    - name: SERVING_REQUEST_METRICS_BACKEND\n",
      "      value: prometheus\n",
      "    - name: TRACING_CONFIG_BACKEND\n",
      "      value: none\n",
      "    - name: TRACING_CONFIG_ZIPKIN_ENDPOINT\n",
      "    - name: TRACING_CONFIG_DEBUG\n",
      "      value: \"false\"\n",
      "    - name: TRACING_CONFIG_SAMPLE_RATE\n",
      "      value: \"0.1\"\n",
      "    - name: USER_PORT\n",
      "      value: \"8080\"\n",
      "    - name: SYSTEM_NAMESPACE\n",
      "      value: knative-serving\n",
      "    - name: METRICS_DOMAIN\n",
      "      value: knative.dev/internal/serving\n",
      "    - name: SERVING_READINESS_PROBE\n",
      "      value: '{\"tcpSocket\":{\"port\":8080,\"host\":\"127.0.0.1\"},\"successThreshold\":1}'\n",
      "    - name: ENABLE_PROFILING\n",
      "      value: \"false\"\n",
      "    - name: SERVING_ENABLE_PROBE_REQUEST_LOG\n",
      "      value: \"false\"\n",
      "    - name: METRICS_COLLECTOR_ADDRESS\n",
      "    - name: CONCURRENCY_STATE_ENDPOINT\n",
      "    - name: CONCURRENCY_STATE_TOKEN_PATH\n",
      "      value: /var/run/secrets/tokens/state-token\n",
      "    - name: HOST_IP\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: status.hostIP\n",
      "    - name: ENABLE_HTTP2_AUTO_DETECTION\n",
      "      value: \"false\"\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/serving-cmd-queue:v1.2.5\n",
      "    imagePullPolicy: IfNotPresent\n",
      "    name: queue-proxy\n",
      "    ports:\n",
      "    - containerPort: 8022\n",
      "      name: http-queueadm\n",
      "      protocol: TCP\n",
      "    - containerPort: 9090\n",
      "      name: http-autometric\n",
      "      protocol: TCP\n",
      "    - containerPort: 9091\n",
      "      name: http-usermetric\n",
      "      protocol: TCP\n",
      "    - containerPort: 8012\n",
      "      name: queue-port\n",
      "      protocol: TCP\n",
      "    readinessProbe:\n",
      "      failureThreshold: 3\n",
      "      httpGet:\n",
      "        httpHeaders:\n",
      "        - name: K-Network-Probe\n",
      "          value: queue\n",
      "        path: /app-health/queue-proxy/readyz\n",
      "        port: 15020\n",
      "        scheme: HTTP\n",
      "      periodSeconds: 10\n",
      "      successThreshold: 1\n",
      "      timeoutSeconds: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        cpu: 25m\n",
      "        memory: 400Mi\n",
      "    securityContext:\n",
      "      allowPrivilegeEscalation: false\n",
      "      capabilities:\n",
      "        drop:\n",
      "        - all\n",
      "      readOnlyRootFilesystem: true\n",
      "      runAsNonRoot: true\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: File\n",
      "    volumeMounts:\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: kube-api-access-v8s8n\n",
      "      readOnly: true\n",
      "  - args:\n",
      "    - proxy\n",
      "    - sidecar\n",
      "    - --domain\n",
      "    - $(POD_NAMESPACE).svc.cluster.local\n",
      "    - --proxyLogLevel=warning\n",
      "    - --proxyComponentLogLevel=misc:error\n",
      "    - --log_output_level=default:info\n",
      "    - --concurrency\n",
      "    - \"2\"\n",
      "    env:\n",
      "    - name: JWT_POLICY\n",
      "      value: third-party-jwt\n",
      "    - name: PILOT_CERT_PROVIDER\n",
      "      value: istiod\n",
      "    - name: CA_ADDR\n",
      "      value: istiod.istio-system.svc:15012\n",
      "    - name: POD_NAME\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: metadata.name\n",
      "    - name: POD_NAMESPACE\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: metadata.namespace\n",
      "    - name: INSTANCE_IP\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: status.podIP\n",
      "    - name: SERVICE_ACCOUNT\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: spec.serviceAccountName\n",
      "    - name: HOST_IP\n",
      "      valueFrom:\n",
      "        fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: status.hostIP\n",
      "    - name: PROXY_CONFIG\n",
      "      value: |\n",
      "        {}\n",
      "    - name: ISTIO_META_POD_PORTS\n",
      "      value: |-\n",
      "        [\n",
      "            {\"name\":\"user-port\",\"containerPort\":8080,\"protocol\":\"TCP\"}\n",
      "            ,{\"name\":\"http-queueadm\",\"containerPort\":8022,\"protocol\":\"TCP\"}\n",
      "            ,{\"name\":\"http-autometric\",\"containerPort\":9090,\"protocol\":\"TCP\"}\n",
      "            ,{\"name\":\"http-usermetric\",\"containerPort\":9091,\"protocol\":\"TCP\"}\n",
      "            ,{\"name\":\"queue-port\",\"containerPort\":8012,\"protocol\":\"TCP\"}\n",
      "        ]\n",
      "    - name: ISTIO_META_APP_CONTAINERS\n",
      "      value: kserve-container,queue-proxy\n",
      "    - name: ISTIO_META_CLUSTER_ID\n",
      "      value: Kubernetes\n",
      "    - name: ISTIO_META_INTERCEPTION_MODE\n",
      "      value: REDIRECT\n",
      "    - name: ISTIO_META_WORKLOAD_NAME\n",
      "      value: torchserve-401a30c0-predictor-default-00001-deployment\n",
      "    - name: ISTIO_META_OWNER\n",
      "      value: kubernetes://apis/apps/v1/namespaces/kbm-u-tutorial/deployments/torchserve-401a30c0-predictor-default-00001-deployment\n",
      "    - name: ISTIO_META_MESH_ID\n",
      "      value: cluster.local\n",
      "    - name: TRUST_DOMAIN\n",
      "      value: cluster.local\n",
      "    - name: ISTIO_KUBE_APP_PROBERS\n",
      "      value: '{\"/app-health/queue-proxy/readyz\":{\"httpGet\":{\"path\":\"/\",\"port\":8012,\"scheme\":\"HTTP\",\"httpHeaders\":[{\"name\":\"K-Network-Probe\",\"value\":\"queue\"}]},\"timeoutSeconds\":1}}'\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2:1.14.1\n",
      "    imagePullPolicy: IfNotPresent\n",
      "    name: istio-proxy\n",
      "    ports:\n",
      "    - containerPort: 15090\n",
      "      name: http-envoy-prom\n",
      "      protocol: TCP\n",
      "    readinessProbe:\n",
      "      failureThreshold: 30\n",
      "      httpGet:\n",
      "        path: /healthz/ready\n",
      "        port: 15021\n",
      "        scheme: HTTP\n",
      "      initialDelaySeconds: 1\n",
      "      periodSeconds: 2\n",
      "      successThreshold: 1\n",
      "      timeoutSeconds: 3\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: \"2\"\n",
      "        memory: 1Gi\n",
      "      requests:\n",
      "        cpu: 10m\n",
      "        memory: 40Mi\n",
      "    securityContext:\n",
      "      allowPrivilegeEscalation: false\n",
      "      capabilities:\n",
      "        drop:\n",
      "        - ALL\n",
      "      privileged: false\n",
      "      readOnlyRootFilesystem: true\n",
      "      runAsGroup: 1337\n",
      "      runAsNonRoot: true\n",
      "      runAsUser: 1337\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: File\n",
      "    volumeMounts:\n",
      "    - mountPath: /var/run/secrets/workload-spiffe-uds\n",
      "      name: workload-socket\n",
      "    - mountPath: /var/run/secrets/workload-spiffe-credentials\n",
      "      name: workload-certs\n",
      "    - mountPath: /var/run/secrets/istio\n",
      "      name: istiod-ca-cert\n",
      "    - mountPath: /var/lib/istio/data\n",
      "      name: istio-data\n",
      "    - mountPath: /etc/istio/proxy\n",
      "      name: istio-envoy\n",
      "    - mountPath: /var/run/secrets/tokens\n",
      "      name: istio-token\n",
      "    - mountPath: /etc/istio/pod\n",
      "      name: istio-podinfo\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: kube-api-access-v8s8n\n",
      "      readOnly: true\n",
      "  dnsPolicy: ClusterFirst\n",
      "  enableServiceLinks: false\n",
      "  initContainers:\n",
      "  - args:\n",
      "    - /mnt/pvc/fmnist_model\n",
      "    - /mnt/models\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-storage-initializer:v0.8.0\n",
      "    imagePullPolicy: IfNotPresent\n",
      "    name: storage-initializer\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: \"1\"\n",
      "        memory: 1Gi\n",
      "      requests:\n",
      "        cpu: 100m\n",
      "        memory: 100Mi\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: FallbackToLogsOnError\n",
      "    volumeMounts:\n",
      "    - mountPath: /mnt/pvc\n",
      "      name: kserve-pvc-source\n",
      "      readOnly: true\n",
      "    - mountPath: /mnt/models\n",
      "      name: kserve-provision-location\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: kube-api-access-v8s8n\n",
      "      readOnly: true\n",
      "  - args:\n",
      "    - istio-iptables\n",
      "    - -p\n",
      "    - \"15001\"\n",
      "    - -z\n",
      "    - \"15006\"\n",
      "    - -u\n",
      "    - \"1337\"\n",
      "    - -m\n",
      "    - REDIRECT\n",
      "    - -i\n",
      "    - '*'\n",
      "    - -x\n",
      "    - \"\"\n",
      "    - -b\n",
      "    - '*'\n",
      "    - -d\n",
      "    - 15090,15021,15020\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2:1.14.1\n",
      "    imagePullPolicy: IfNotPresent\n",
      "    name: istio-init\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: \"2\"\n",
      "        memory: 1Gi\n",
      "      requests:\n",
      "        cpu: 10m\n",
      "        memory: 40Mi\n",
      "    securityContext:\n",
      "      allowPrivilegeEscalation: false\n",
      "      capabilities:\n",
      "        add:\n",
      "        - NET_ADMIN\n",
      "        - NET_RAW\n",
      "        drop:\n",
      "        - ALL\n",
      "      privileged: false\n",
      "      readOnlyRootFilesystem: false\n",
      "      runAsGroup: 0\n",
      "      runAsNonRoot: false\n",
      "      runAsUser: 0\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: File\n",
      "    volumeMounts:\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: kube-api-access-v8s8n\n",
      "      readOnly: true\n",
      "  nodeName: host-172-16-1-154\n",
      "  preemptionPolicy: PreemptLowerPriority\n",
      "  priority: 0\n",
      "  restartPolicy: Always\n",
      "  schedulerName: default-scheduler\n",
      "  securityContext:\n",
      "    fsGroup: 1337\n",
      "  serviceAccount: default\n",
      "  serviceAccountName: default\n",
      "  terminationGracePeriodSeconds: 60\n",
      "  tolerations:\n",
      "  - effect: NoExecute\n",
      "    key: node.kubernetes.io/not-ready\n",
      "    operator: Exists\n",
      "    tolerationSeconds: 300\n",
      "  - effect: NoExecute\n",
      "    key: node.kubernetes.io/unreachable\n",
      "    operator: Exists\n",
      "    tolerationSeconds: 300\n",
      "  volumes:\n",
      "  - emptyDir: {}\n",
      "    name: workload-socket\n",
      "  - emptyDir: {}\n",
      "    name: workload-certs\n",
      "  - emptyDir:\n",
      "      medium: Memory\n",
      "    name: istio-envoy\n",
      "  - emptyDir: {}\n",
      "    name: istio-data\n",
      "  - downwardAPI:\n",
      "      defaultMode: 420\n",
      "      items:\n",
      "      - fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: metadata.labels\n",
      "        path: labels\n",
      "      - fieldRef:\n",
      "          apiVersion: v1\n",
      "          fieldPath: metadata.annotations\n",
      "        path: annotations\n",
      "    name: istio-podinfo\n",
      "  - name: istio-token\n",
      "    projected:\n",
      "      defaultMode: 420\n",
      "      sources:\n",
      "      - serviceAccountToken:\n",
      "          audience: istio-ca\n",
      "          expirationSeconds: 43200\n",
      "          path: istio-token\n",
      "  - configMap:\n",
      "      defaultMode: 420\n",
      "      name: istio-ca-root-cert\n",
      "    name: istiod-ca-cert\n",
      "  - name: kube-api-access-v8s8n\n",
      "    projected:\n",
      "      defaultMode: 420\n",
      "      sources:\n",
      "      - serviceAccountToken:\n",
      "          expirationSeconds: 3607\n",
      "          path: token\n",
      "      - configMap:\n",
      "          items:\n",
      "          - key: ca.crt\n",
      "            path: ca.crt\n",
      "          name: kube-root-ca.crt\n",
      "      - downwardAPI:\n",
      "          items:\n",
      "          - fieldRef:\n",
      "              apiVersion: v1\n",
      "              fieldPath: metadata.namespace\n",
      "            path: namespace\n",
      "  - name: kserve-pvc-source\n",
      "    persistentVolumeClaim:\n",
      "      claimName: test-fmnist-pvc-401a30c0\n",
      "  - emptyDir: {}\n",
      "    name: kserve-provision-location\n",
      "status:\n",
      "  conditions:\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: \"2024-06-02T16:02:12Z\"\n",
      "    status: \"True\"\n",
      "    type: Initialized\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: \"2024-06-02T16:02:15Z\"\n",
      "    status: \"True\"\n",
      "    type: Ready\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: \"2024-06-02T16:02:15Z\"\n",
      "    status: \"True\"\n",
      "    type: ContainersReady\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: \"2024-06-02T16:02:08Z\"\n",
      "    status: \"True\"\n",
      "    type: PodScheduled\n",
      "  containerStatuses:\n",
      "  - containerID: containerd://4cbdae6d31e22915abc037abcc48417fab87e8195cb428c7a5c1cea237e55fa7\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2:1.14.1\n",
      "    imageID: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2@sha256:df69c1a7af7c0113424a48f5075ac6d0894123ec926fdb315e849b4f04e39616\n",
      "    lastState: {}\n",
      "    name: istio-proxy\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    started: true\n",
      "    state:\n",
      "      running:\n",
      "        startedAt: \"2024-06-02T16:02:13Z\"\n",
      "  - containerID: containerd://b93b43add33c68c91e54e2a756a89aa738b4e95965e3cd1f59768c955329fba6\n",
      "    image: sha256:31abca3395d3c7550817919a31598059a53874d7dc685f07798d42225e99e4d8\n",
      "    imageID: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-torchserve-kfs@sha256:47b23a1bac1a4b33e8fbc86cd653a372deb39503a6f54ba790a7433c9b8c6d85\n",
      "    lastState: {}\n",
      "    name: kserve-container\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    started: true\n",
      "    state:\n",
      "      running:\n",
      "        startedAt: \"2024-06-02T16:02:12Z\"\n",
      "  - containerID: containerd://8e8e23521282cdc838b2423bdc6e34bb0991aa37855b836907ecc57d155b50e4\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/serving-cmd-queue:v1.2.5\n",
      "    imageID: bigdata.kr-central-1.kcr.dev/mlops-pipelines/serving-cmd-queue@sha256:2ca2453b63566f0edcaaacd96490701c7158eb8f65044299920b3082e5b6ca94\n",
      "    lastState: {}\n",
      "    name: queue-proxy\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    started: true\n",
      "    state:\n",
      "      running:\n",
      "        startedAt: \"2024-06-02T16:02:12Z\"\n",
      "  hostIP: 172.16.1.154\n",
      "  initContainerStatuses:\n",
      "  - containerID: containerd://2b921d54c8823cd7e10098fe404ad77b439c4aea2250b29917b95a28bf70d58b\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-storage-initializer:v0.8.0\n",
      "    imageID: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-storage-initializer@sha256:e0da87225ddc6a642bb30979cd8a4853c1342fd9200e521c2637b16d8d5f9744\n",
      "    lastState: {}\n",
      "    name: storage-initializer\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    state:\n",
      "      terminated:\n",
      "        containerID: containerd://2b921d54c8823cd7e10098fe404ad77b439c4aea2250b29917b95a28bf70d58b\n",
      "        exitCode: 0\n",
      "        finishedAt: \"2024-06-02T16:02:10Z\"\n",
      "        reason: Completed\n",
      "        startedAt: \"2024-06-02T16:02:09Z\"\n",
      "  - containerID: containerd://eebfe1a7780ed6a5f187babf0fb8667dc591556eb24c1a9a04f71cdd992fe1f6\n",
      "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2:1.14.1\n",
      "    imageID: bigdata.kr-central-1.kcr.dev/mlops-pipelines/istio-proxyv2@sha256:df69c1a7af7c0113424a48f5075ac6d0894123ec926fdb315e849b4f04e39616\n",
      "    lastState: {}\n",
      "    name: istio-init\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    state:\n",
      "      terminated:\n",
      "        containerID: containerd://eebfe1a7780ed6a5f187babf0fb8667dc591556eb24c1a9a04f71cdd992fe1f6\n",
      "        exitCode: 0\n",
      "        finishedAt: \"2024-06-02T16:02:11Z\"\n",
      "        reason: Completed\n",
      "        startedAt: \"2024-06-02T16:02:11Z\"\n",
      "  phase: Running\n",
      "  podIP: 192.168.186.151\n",
      "  podIPs:\n",
      "  - ip: 192.168.186.151\n",
      "  qosClass: Burstable\n",
      "  startTime: \"2024-06-02T16:02:08Z\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl get po torchserve-401a30c0-predictor-default-00001-deployment-6674nngx -n kbm-u-kubeflow-tutorial -o yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

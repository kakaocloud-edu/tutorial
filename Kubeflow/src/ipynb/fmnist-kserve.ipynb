{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f9ce70-f5b9-44f7-a8a1-506b8a7c92c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T10:08:58.985296Z",
     "iopub.status.busy": "2023-04-15T10:08:58.984964Z",
     "iopub.status.idle": "2023-04-15T10:08:58.988709Z",
     "shell.execute_reply": "2023-04-15T10:08:58.987984Z",
     "shell.execute_reply.started": "2023-04-15T10:08:58.985253Z"
    },
    "tags": []
   },
   "source": [
    "# 노트북에서 모델 학습 및 서빙 API 생성 파이프라인 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda13f19-1c7a-443b-ac17-39360e99282d",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 추가 및 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da6808-809e-4808-ace3-007b3af063fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import uuid\n",
    "from kakaocloud_kbm import KbmPipelineClient\n",
    "import kfp.compiler as compiler\n",
    "from kfp import dsl\n",
    "from kfp.dsl import ContainerOp, pipeline\n",
    "from kfp import components\n",
    "from kfp.components import create_component_from_func\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# Fashion MNIST 데이터셋 URL\n",
    "t10k_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "t10k_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "def download_and_extract(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.open(BytesIO(response.content), 'rb') as f:\n",
    "        return np.frombuffer(f.read(), np.uint8)\n",
    "\n",
    "t10k_images = download_and_extract(t10k_images_url)[16:].reshape(-1, 28, 28)\n",
    "t10k_labels = download_and_extract(t10k_labels_url)[8:]\n",
    "\n",
    "label_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "def show_images(images, labels, label_names, rows=5, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for img, ax, lbl in zip(images, axes, labels):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(label_names[lbl])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(t10k_images[:25], t10k_labels[:25], label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c86503-c723-4e75-a17c-e4429e5c9e85",
   "metadata": {},
   "source": [
    "## 2. 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e8ef6-ca73-45b2-93ee-a0fd3e6a01ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"KUBEFLOW_HOST\"] = \"{https://도메인주소}\" #도메인 주소 마지막에 '/'를 넣지 마세요. ex) https://kakaocloud-edu.com\n",
    "os.environ[\"KUBEFLOW_USERNAME\"] = \"{계정 아이디}\"\n",
    "os.environ[\"KUBEFLOW_PASSWORD\"] = \"{계정 비밀번호}\"\n",
    "\n",
    "# 환경변수들 준비\n",
    "KBM_NAMESPACE = os.environ['NB_PREFIX'].split('/')[2]\n",
    "TRAIN_PATH = 'fmnist_serve_model'\n",
    "TRAIN_CR_IMAGE = \"bigdata-150.kr-central-2.kcr.dev/kc-kubeflow/kmlp-pytorch:1.0.0.py36.cuda\"\n",
    "TASK_UUID = uuid.uuid1().hex[:8]\n",
    "PVC_NAME = f\"test-fmnist-pvc-{TASK_UUID}\"\n",
    "MODEL_NAME = f\"torch-model-{TASK_UUID}\"\n",
    "KBM_MODEL_SERV_NAME = f\"torchserve-{TASK_UUID}\"\n",
    "EPOCH_NUM = 3\n",
    "\n",
    "print(f\"Namespace : {KBM_NAMESPACE}\")\n",
    "print(f\"Train Path : {TRAIN_PATH}\")\n",
    "print(f\"Image for Training : {TRAIN_CR_IMAGE}\")\n",
    "print(f\"Model Name : {MODEL_NAME}\")\n",
    "print(f\"Model PVC Name : {PVC_NAME}\")\n",
    "print(f\"Model Server Name : {KBM_MODEL_SERV_NAME}\")\n",
    "print(f\"Number of Epochs : {EPOCH_NUM}\")\n",
    "\n",
    "# 학습을 위한 폴더 생성\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4fc1be-4c50-4e87-93af-a5e35a71ce73",
   "metadata": {},
   "source": [
    "## 3. 파이프라인 컴포넌트 빌드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc77d5b-8570-4b7d-9682-39e07dcc7f9d",
   "metadata": {},
   "source": [
    "### 3-1. 데이터셋 준비 컴포넌트: Fashion MNIST 데이터셋을 다운로드하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66cfe7-525c-4144-a1f9-6ef41f992b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_fashion_mnist(\n",
    "    t10k_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz',\n",
    "    t10k_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
    "    train_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz',\n",
    "    train_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'\n",
    "):\n",
    "    import os\n",
    "    import requests\n",
    "    import gzip\n",
    "\n",
    "    def download_and_save(url, output_path):\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        with gzip.open(output_path, 'rb') as f_in:\n",
    "            with open(output_path.rstrip('.gz'), 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "    os.makedirs('/pvc', exist_ok=True)\n",
    "    download_and_save(t10k_images_url, '/pvc/t10k-images-idx3-ubyte.gz')\n",
    "    download_and_save(t10k_labels_url, '/pvc/t10k-labels-idx1-ubyte.gz')\n",
    "    download_and_save(train_images_url, '/pvc/train-images-idx3-ubyte.gz')\n",
    "    download_and_save(train_labels_url, '/pvc/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "    return '/pvc'\n",
    "\n",
    "dataset_op = create_component_from_func(\n",
    "    download_fashion_mnist,\n",
    "    output_component_file=f'{TRAIN_PATH}/data_component.yaml',\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['requests']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e156c-16c3-4618-a274-bd4e9314ba56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {TRAIN_PATH}/dataset_component.yaml\n",
    "name: Fashion MNIST Dataset\n",
    "description: |\n",
    "  Fashion MNIST Dataset: https://github.com/zalandoresearch/fashion-mnist\n",
    "metadata:\n",
    "  annotations:\n",
    "    author: KiC Bigdata <bigdata.platform@kakaoenterprise.com>\n",
    "inputs:\n",
    "- {name: t10k_images_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'}\n",
    "- {name: t10k_labels_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'}\n",
    "- {name: train_images_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz'}\n",
    "- {name: train_labels_url, type: String, default: 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz'}\n",
    "implementation:\n",
    "  container:\n",
    "    image: curlimages/curl\n",
    "    command:\n",
    "    - sh\n",
    "    - -c\n",
    "    - |\n",
    "      set -e -x -o pipefail\n",
    "      curl -L \"$0\" --output \"/pvc/t10k-images-idx3-ubyte.gz\"\n",
    "      curl -L \"$1\" --output \"/pvc/t10k-labels-idx1-ubyte.gz\"\n",
    "      curl -L \"$2\" --output \"/pvc/train-images-idx3-ubyte.gz\"\n",
    "      curl -L \"$3\" --output \"/pvc/train-labels-idx1-ubyte.gz\"\n",
    "      if [ -s /pvc/t10k-images-idx3-ubyte.gz ] && [ -s /pvc/t10k-labels-idx1-ubyte.gz ] && [ -s /pvc/train-images-idx3-ubyte.gz ] && [ -s /pvc/train-labels-idx1-ubyte.gz ]; then\n",
    "        gzip -d /pvc/t10k-images-idx3-ubyte.gz\n",
    "        gzip -d /pvc/t10k-labels-idx1-ubyte.gz\n",
    "        gzip -d /pvc/train-images-idx3-ubyte.gz\n",
    "        gzip -d /pvc/train-labels-idx1-ubyte.gz\n",
    "      else\n",
    "        echo \"Download failed, exiting.\"\n",
    "        exit 1\n",
    "      fi\n",
    "    - {inputValue: t10k_images_url}\n",
    "    - {inputValue: t10k_labels_url}\n",
    "    - {inputValue: train_images_url}\n",
    "    - {inputValue: train_labels_url}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2042056-eeb1-49ef-a176-53fae491f973",
   "metadata": {},
   "source": [
    "### 3-2. Fashion MNIST 모델 학습 및 서빙 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae22e3-9e21-487a-a1d7-b7a012b5446a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fmnist(\n",
    "    epoch_num: str,\n",
    "    model_name: str,\n",
    "    train_images_path: str,\n",
    "    train_labels_path: str,\n",
    "    test_images_path: str,\n",
    "    test_labels_path: str\n",
    "):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torchvision import transforms\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from PIL import Image\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    class FashionMNISTDataset(Dataset):\n",
    "        def __init__(self, images_path, labels_path, transform=None):\n",
    "            self.images = self._read_images(images_path)\n",
    "            self.labels = self._read_labels(labels_path)\n",
    "            self.transform = transform\n",
    "\n",
    "        def _read_images(self, path):\n",
    "            with open(path, 'rb') as f:\n",
    "                images = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "            images = images.reshape(-1, 28, 28, 1)  # Ensure the shape is [num_samples, 28, 28, 1]\n",
    "            return images\n",
    "\n",
    "        def _read_labels(self, path):\n",
    "            with open(path, 'rb') as f:\n",
    "                labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            return labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            image = Image.fromarray(image.squeeze(), mode='L')  # Convert to PIL Image\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, torch.tensor(label, dtype=torch.long)  # Convert label to LongTensor\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 7 * 7)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    train_dataset = FashionMNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "    test_dataset = FashionMNISTDataset(test_images_path, test_labels_path, transform=transform)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Model Training\n",
    "    model = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(int(epoch_num)):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    \n",
    "                print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    os.makedirs('/pvc/fmnist_model', exist_ok=True)\n",
    "    torch.save(model.state_dict(), '/pvc/fmnist_model/fmnist_cnn.pth')\n",
    "\n",
    "    # Save handler.py\n",
    "    handler_code = \"\"\"\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import logging\n",
    "import base64\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('mylog - %(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "class ImageClassifierHandler(BaseHandler):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, context):\n",
    "        import torch.nn as nn  # add import here\n",
    "        logger.info(\"Initializing handler...\")\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Net, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "                self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "                self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "                self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(torch.relu(self.conv1(x)))\n",
    "                x = self.pool(torch.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 64 * 7 * 7)\n",
    "                x = torch.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "\n",
    "        self.manifest = context.manifest\n",
    "        properties = context.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model_path = model_dir + '/fmnist_cnn.pth'\n",
    "        logger.info(f\"Loading model from {model_path}\")\n",
    "        try:\n",
    "            self.model = Net()\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            logger.info(\"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            raise e\n",
    "\n",
    "        self.image_processing = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        self.initialized = True\n",
    "        logger.info(\"Handler initialized successfully.\")\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        logger.info(\"Preprocessing input data...\")\n",
    "        try:\n",
    "            image = data[0].get(\"data\") or data[0].get(\"body\")\n",
    "            if isinstance(image, str):\n",
    "                image = io.BytesIO(base64.b64decode(image))\n",
    "            else:\n",
    "                image = io.BytesIO(image)\n",
    "            image = Image.open(image)\n",
    "            image = self.image_processing(image)\n",
    "            logger.info(\"Preprocessing completed.\")\n",
    "            return image.unsqueeze(0).to(self.device)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in preprocessing: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def inference(self, img):\n",
    "        logger.info(\"Running inference...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output = self.model(img)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "            logger.info(f\"Inference completed. Prediction: {predicted.item()}\")\n",
    "            return predicted\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in inference: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        logger.info(\"Postprocessing inference output...\")\n",
    "        try:\n",
    "            result = [int(inference_output[0])]\n",
    "            logger.info(f\"Postprocessing completed. Result: {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in postprocessing: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def handle(self, data, context):\n",
    "        logger.info(\"Handling request...\")\n",
    "        try:\n",
    "            if not self.initialized:\n",
    "                self.initialize(context)\n",
    "            data = self.preprocess(data)\n",
    "            data = self.inference(data)\n",
    "            data = self.postprocess(data)\n",
    "            logger.info(\"Request handled successfully.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in handle: {e}\")\n",
    "            raise e\n",
    "\"\"\"\n",
    "\n",
    "    with open(\"/pvc/fmnist_model/handler.py\", \"w\") as f:\n",
    "        f.write(handler_code)\n",
    "        \n",
    "    \n",
    "    # config for torchserve\n",
    "    import json\n",
    "    config = dict(\n",
    "        inference_address=\"http://0.0.0.0:8085\",\n",
    "        management_address=\"http://0.0.0.0:8085\",\n",
    "        metrics_address=\"http://0.0.0.0:8082\",\n",
    "        grpc_inference_port=7070,\n",
    "        grpc_management_port=7071,\n",
    "        enable_envvars_config=\"true\",\n",
    "        install_py_dep_per_model=\"true\",\n",
    "        model_store=\"/mnt/pvc/fmnist_model/model-store\",\n",
    "        model_snapshot=json.dumps({\n",
    "            \"name\": \"startup.cfg\",\n",
    "            \"modelCount\": 1,\n",
    "            \"models\": {\n",
    "                f\"{model_name}\": {  # Model Name\n",
    "                    \"1.0\": {\n",
    "                        \"defaultVersion\": \"true\",\n",
    "                        \"marName\": f\"{model_name}.mar\",\n",
    "                        \"minWorkers\": 1,\n",
    "                        \"maxWorkers\": 5,\n",
    "                        \"batchSize\": 1,\n",
    "                        \"maxBatchDelay\": 10,\n",
    "                        \"responseTimeout\": 60,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }),\n",
    "    )\n",
    "    # creating config & config folder\n",
    "    if not os.path.exists(\"/pvc/fmnist_model/config\"):\n",
    "        os.mkdir(\"/pvc/fmnist_model/config\")\n",
    "        \n",
    "    with open(\"/pvc/fmnist_model/config/config.properties\", \"w\") as f:\n",
    "        for i, j in config.items():\n",
    "            f.write(f\"{i}={j}\\n\")\n",
    "            \n",
    "train_fmnist_op = components.create_component_from_func(\n",
    "    train_fmnist, \n",
    "    output_component_file=f'{TRAIN_PATH}/train_component.yaml',\n",
    "    base_image=TRAIN_CR_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bbc0f-bead-4b6f-b7ab-f29a3c6ef3be",
   "metadata": {},
   "source": [
    "### 3-3. 서빙을 위한 MAR 파일 생성 컴포넌트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43082c-e400-45f8-9021-e733d27ad623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_marfile():\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"Creating Marfile\",\n",
    "        command=[\"/bin/sh\"],\n",
    "        image=\"python:3.9\",\n",
    "        arguments=[\n",
    "            \"-c\",\n",
    "            f\"cd /pvc/fmnist_model; pip install torchserve torch-model-archiver torch-workflow-archiver; torch-model-archiver --model-name {MODEL_NAME} --version 1.0 --serialized-file fmnist_cnn.pth --handler handler.py --force; mkdir model-store; mv -f {MODEL_NAME}.mar model-store\"\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c464786-81ad-48e9-ac1d-d2b22f49f0d6",
   "metadata": {},
   "source": [
    "### 3-4. KServe 컴포넌트 YAML 파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308d40-be20-4788-b500-5bd0b176c1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {TRAIN_PATH}/kserve_component.yaml\n",
    "name: Serve a model with KServe \n",
    "description: Serve Models using KServe \n",
    "inputs:\n",
    "  - {name: Action,                    type: String, default: 'create',     description: 'Action to execute on KServe'}\n",
    "  - {name: Model Name,                type: String, default: '',           description: 'Name to give to the deployed model'}\n",
    "  - {name: Model URI,                 type: String, default: '',           description: 'Path of the S3 or GCS compatible directory containing the model.'}\n",
    "  - {name: Canary Traffic Percent,    type: String, default: '100',        description: 'The traffic split percentage between the candidate model and the last ready model'}\n",
    "  - {name: Namespace,                 type: String, default: '',           description: 'Kubernetes namespace where the KServe service is deployed.'}\n",
    "  - {name: Framework,                 type: String, default: '',           description: 'Machine Learning Framework for Model Serving.'}\n",
    "  - {name: Custom Model Spec,         type: String, default: '{}',         description: 'Custom model runtime container spec in JSON'}\n",
    "  - {name: Autoscaling Target,        type: String, default: '0',          description: 'Autoscaling Target Number'}\n",
    "  - {name: Service Account,           type: String, default: '',           description: 'ServiceAccount to use to run the InferenceService pod'}\n",
    "  - {name: Enable Istio Sidecar,      type: Bool,   default: 'True',       description: 'Whether to enable istio sidecar injection'}\n",
    "  - {name: InferenceService YAML,     type: String, default: '{}',         description: 'Raw InferenceService serialized YAML for deployment'}\n",
    "  - {name: Watch Timeout,             type: String, default: '300',        description: \"Timeout seconds for watching until InferenceService becomes ready.\"}\n",
    "  - {name: Min Replicas,              type: String, default: '-1',         description: 'Minimum number of InferenceService replicas'}\n",
    "  - {name: Max Replicas,              type: String, default: '-1',         description: 'Maximum number of InferenceService replicas'}\n",
    "  - {name: Request Timeout,           type: String, default: '60',         description: \"Specifies the number of seconds to wait before timing out a request to the component.\"}\n",
    "  - {name: Enable ISVC Status,        type: Bool,   default: 'True',       description: \"Specifies whether to store the inference service status as the output parameter\"}\n",
    "\n",
    "outputs:\n",
    "  - {name: InferenceService Status,   type: String,                        description: 'Status JSON output of InferenceService'}\n",
    "implementation:\n",
    "  container:\n",
    "    image: bigdata.kr-central-1.kcr.dev/mlops-pipelines/kserve-component:v0.7.0.kbm.1c\n",
    "    command: ['python']\n",
    "    args: [\n",
    "      -u, kservedeployer.py,\n",
    "      --action,                 {inputValue: Action},\n",
    "      --model-name,             {inputValue: Model Name},\n",
    "      --model-uri,              {inputValue: Model URI},\n",
    "      --canary-traffic-percent, {inputValue: Canary Traffic Percent},\n",
    "      --namespace,              {inputValue: Namespace},\n",
    "      --framework,              {inputValue: Framework},\n",
    "      --custom-model-spec,      {inputValue: Custom Model Spec},\n",
    "      --autoscaling-target,     {inputValue: Autoscaling Target},\n",
    "      --service-account,        {inputValue: Service Account},\n",
    "      --enable-istio-sidecar,   {inputValue: Enable Istio Sidecar},\n",
    "      --output-path,            {outputPath: InferenceService Status},\n",
    "      --inferenceservice-yaml,  {inputValue: InferenceService YAML},\n",
    "      --watch-timeout,          {inputValue: Watch Timeout},\n",
    "      --min-replicas,           {inputValue: Min Replicas},\n",
    "      --max-replicas,           {inputValue: Max Replicas},\n",
    "      --request-timeout,        {inputValue: Request Timeout},\n",
    "      --enable-isvc-status,     {inputValue: Enable ISVC Status}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c9a76-df2a-4b42-a99e-be69933bd760",
   "metadata": {},
   "source": [
    "### 3-5. KServe 인퍼런스 모델 생성 컴포넌트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982dcbfa-1c5a-4265-ae21-422c4c0eb31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.components import load_component_from_file\n",
    "\n",
    "def create_inference_model():\n",
    "    kserve_op = load_component_from_file(f'{TRAIN_PATH}/kserve_component.yaml')\n",
    "    \n",
    "    model_name = KBM_MODEL_SERV_NAME\n",
    "    namespace = KBM_NAMESPACE\n",
    "    model_uri = f\"pvc://{PVC_NAME}/fmnist_model\"\n",
    "    framework=\"pytorch\"\n",
    "    \n",
    "    opt = kserve_op(action=\"apply\",\n",
    "              model_name=model_name,\n",
    "              model_uri=model_uri,\n",
    "              namespace=namespace,\n",
    "              framework=framework)\n",
    "    \n",
    "    opt.set_cpu_limit(cpu=\"2\").set_memory_limit(memory=\"4G\")\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45f4bc-c22a-4e60-b580-2ed86f34fd1d",
   "metadata": {},
   "source": [
    "## 4. 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7febc1-7fe5-4472-b876-e1a36cf80622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Fashion MNIST Model Pipeline\"\n",
    ")\n",
    "def fmnist_model_pipeline(\n",
    "    t10k_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz',\n",
    "    t10k_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
    "    train_images_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz',\n",
    "    train_labels_url: str = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz',\n",
    "    model_name: str = \"torch-model\",\n",
    "    epoch_num: str = \"4\"\n",
    "):\n",
    "    \n",
    "    vop = dsl.VolumeOp(\n",
    "        name=\"volume_creation\",\n",
    "        resource_name=PVC_NAME,\n",
    "        generate_unique_name=False,\n",
    "        size=\"10Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "    \n",
    "    download_data = dataset_op(\n",
    "        t10k_images_url=t10k_images_url,\n",
    "        t10k_labels_url=t10k_labels_url,\n",
    "        train_images_url=train_images_url,\n",
    "        train_labels_url=train_labels_url\n",
    "    ).add_pvolumes({\"/pvc\": vop.volume})\n",
    "    download_data.set_cpu_limit(cpu=\"1\").set_memory_limit(memory=\"2G\")\n",
    "\n",
    "    model_train = train_fmnist_op(\n",
    "        epoch_num,\n",
    "        model_name,\n",
    "        '/pvc/train-images-idx3-ubyte',\n",
    "        '/pvc/train-labels-idx1-ubyte',\n",
    "        '/pvc/t10k-images-idx3-ubyte',\n",
    "        '/pvc/t10k-labels-idx1-ubyte'\n",
    "    ).add_node_selector_constraint(\n",
    "        'nvidia.com/gpu.present', 'true' # GPU 사용 활성화\n",
    "    ).add_pvolumes({\"/pvc\": vop.volume})\n",
    "    \n",
    "    model_train.add_resource_limit(\n",
    "        \"nvidia.com/mig-1g.10gb\", \"1\"\n",
    "    )\n",
    "    model_train.set_cpu_limit(cpu=\"4\").set_memory_limit(memory=\"8G\")\n",
    "    model_train.set_display_name(\"Training Fashion MNIST Model\")\n",
    "    model_train.after(download_data)\n",
    "    \n",
    "    marfile = create_marfile()\n",
    "    marfile.add_pvolumes({\"/pvc\": vop.volume})\n",
    "    marfile.set_display_name(\"Creating Marfile\")\n",
    "    marfile.execution_options.caching_strategy.max_cache_staleness = \"P0D\" # cache 사용않는 옵션\n",
    "    marfile.set_cpu_limit(cpu=\"1\").set_memory_limit(memory=\"2G\")\n",
    "    marfile.after(model_train)\n",
    "\n",
    "    inference_model = create_inference_model()\n",
    "    inference_model.add_pvolumes({\"/pvc\": vop.volume})\n",
    "    inference_model.set_cpu_limit(cpu=\"4\").set_memory_limit(memory=\"8G\")\n",
    "    inference_model.after(marfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35aa31-2d06-478f-af69-5de5da953374",
   "metadata": {},
   "source": [
    "## 5. 파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e991c3-aa62-458a-b1c1-70232f518bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = fmnist_model_pipeline.__name__ + ' test experiment'\n",
    "run_name = fmnist_model_pipeline.__name__ + ' run'\n",
    "\n",
    "print(\"experiment_name: \" + experiment_name)\n",
    "print(\"run_name: \" + run_name)\n",
    "\n",
    "arguments = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"epoch_num\": str(EPOCH_NUM)\n",
    "}\n",
    "\n",
    "client = KbmPipelineClient()\n",
    "client.create_run_from_pipeline_func(\n",
    "    fmnist_model_pipeline, \n",
    "    experiment_name=experiment_name, \n",
    "    run_name=run_name, \n",
    "    arguments=arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b045a9e-62c0-43e8-80ce-c27e7075d031",
   "metadata": {},
   "source": [
    "## 6. 모델 서빙 API 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c5c1f-fbb1-4947-8e36-770b5f7aa68a",
   "metadata": {},
   "source": [
    "### 6-1. 모델 서빙 API 테스트 이미지 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d96abd-cd35-4312-8420-847843dfa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# Fashion MNIST 데이터셋 URL\n",
    "t10k_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "t10k_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# 데이터 다운로드 및 압축 해제 함수\n",
    "def download_and_extract(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.open(BytesIO(response.content), 'rb') as f:\n",
    "        return np.frombuffer(f.read(), np.uint8)\n",
    "\n",
    "# 데이터 다운로드 및 로드\n",
    "t10k_images = download_and_extract(t10k_images_url)[16:].reshape(-1, 28, 28)\n",
    "t10k_labels = download_and_extract(t10k_labels_url)[8:]\n",
    "\n",
    "# 라벨 이름 정의\n",
    "label_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "# 랜덤 이미지 선택 및 출력 함수\n",
    "def get_random_image(images, labels):\n",
    "    random_idx = np.random.randint(len(images))\n",
    "    random_image = images[random_idx]\n",
    "    random_label = labels[random_idx]\n",
    "    return random_image, random_label\n",
    "\n",
    "def show_image(image, label, label_names):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Label: {label} ({label_names[label]})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 랜덤 이미지 선택\n",
    "random_image, random_label = get_random_image(t10k_images, t10k_labels)\n",
    "\n",
    "# 랜덤 이미지 출력\n",
    "show_image(random_image, random_label, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ddfbb-8d9e-4fc1-aa02-bcd84a8af13d",
   "metadata": {},
   "source": [
    "### 6-2. 모델 서빙 API 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0fbbd-9df7-41f2-b109-16de95ac27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 설정 변수\n",
    "KBM_NAMESPACE = os.environ['NB_PREFIX'].split('/')[2]\n",
    "KUBEFLOW_HOST = os.environ[\"KUBEFLOW_HOST\"]\n",
    "KUBEFLOW_USERNAME = os.environ[\"KUBEFLOW_USERNAME\"]\n",
    "KUBEFLOW_PASSWORD = os.environ[\"KUBEFLOW_PASSWORD\"]\n",
    "MODEL_NAME = f\"torch-model-{TASK_UUID}\"\n",
    "KBM_MODEL_SERV_NAME = f\"torchserve-{TASK_UUID}\"\n",
    "\n",
    "def get_authenticated_session():\n",
    "    session = requests.Session()\n",
    "    if KUBEFLOW_HOST.startswith(\"https\"):\n",
    "        _kargs = {\"verify\": False}\n",
    "    else:\n",
    "        _kargs = {}\n",
    "\n",
    "    response = session.get(KUBEFLOW_HOST, **_kargs)\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    session.post(response.url, headers=headers, data={\"login\": KUBEFLOW_USERNAME, \"password\": KUBEFLOW_PASSWORD})\n",
    "    session_cookie = session.cookies.get_dict()[\"authservice_session\"]\n",
    "    return session, session_cookie, _kargs\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def send_test_request(image, session, session_cookie, _kargs):\n",
    "    input_image_data = encode_image_to_base64(image)\n",
    "    data = {\"instances\": [{\"data\": input_image_data}]}\n",
    "    endpoint = f\"{KUBEFLOW_HOST}/v1/models/{MODEL_NAME}:predict\"\n",
    "    print(f\"endpoint: {endpoint}\")\n",
    "\n",
    "    response = session.post(\n",
    "        url=endpoint,\n",
    "        cookies={'authservice_session': session_cookie},\n",
    "        headers={\"Host\": f\"{KBM_MODEL_SERV_NAME}.{KBM_NAMESPACE}.{KUBEFLOW_HOST.split('/')[2]}\"},\n",
    "        json=data,\n",
    "        **_kargs\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except ValueError:\n",
    "        print(f\"Error: Unable to parse JSON response. Response text: {response.text}\")\n",
    "        return None\n",
    "    \n",
    "    return response_json\n",
    "\n",
    "session, session_cookie, _kargs = get_authenticated_session()\n",
    "\n",
    "# 사용자 이미지 로드\n",
    "#image = np.array(Image.open('dress.png'))\n",
    "#random_label = None\n",
    "\n",
    "response = send_test_request(random_image, session, session_cookie, _kargs)\n",
    "if response:\n",
    "    predicted_label = response['predictions'][0]\n",
    "    print(predicted_label)\n",
    "    if random_label is not None:\n",
    "        print(f\"입력 라벨: {label_names[random_label]}\")\n",
    "    print(f\"예측 라벨: {label_names[predicted_label]}\")\n",
    "else:\n",
    "    print(\"Failed to get prediction from the model server.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d8e81-3b82-4b30-b74b-1405f7717b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get inferenceservices -n kbm-u-kubeflow-tutorial -o yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c32e4-1367-4090-b719-0bd62df49f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get po -n kbm-u-kubeflow-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4797de4-12aa-4f6a-b7fe-d7b5d12bc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get po torchserve-401a30c0-predictor-default-00001-deployment-6674nngx -n kbm-u-kubeflow-tutorial -o yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18088e9e-1498-40dc-b7fa-54eb2607dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP: 2.11.0\n",
      "PVC: fmnist-pvc-1831fc9a | Model: torch-model-1831fe0c | ISVC: torchserve-1831fef2\n"
     ]
    }
   ],
   "source": [
    "# 0. ê¸°ë³¸ ì„¤ì • (ì œê³µí•´ì£¼ì‹  ì„±ë³„ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ ìŠ¤íƒ€ì¼)\n",
    "import kfp, uuid, os\n",
    "print(\"KFP:\", kfp.__version__)\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.dsl import component, pipeline\n",
    "from kfp import kubernetes as k8s   # â† ì´ê²Œ í•µì‹¬!\n",
    "\n",
    "# ê³µí†µ ë³€ìˆ˜\n",
    "NAMESPACE = os.environ['NB_PREFIX'].split('/')[2]\n",
    "PVC_NAME   = f\"fmnist-pvc-{uuid.uuid1().hex[:8]}\"\n",
    "MODEL_NAME = f\"torch-model-{uuid.uuid1().hex[:8]}\"\n",
    "ISVC_NAME  = f\"torchserve-{uuid.uuid1().hex[:8]}\"\n",
    "EPOCHS     = 3\n",
    "\n",
    "print(f\"PVC: {PVC_NAME} | Model: {MODEL_NAME} | ISVC: {ISVC_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2efe18-27ce-4439-8d0d-0216b8cbf145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f11517a-96b2-4670-bd83-8b1852b5bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/fmnist-pvc-1831fc9a created\n",
      "PVC ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 1. PVC ë¯¸ë¦¬ ìƒì„± (ë…¸íŠ¸ë¶ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "import subprocess, textwrap\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"-\"], input=textwrap.dedent(f\"\"\"\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: {PVC_NAME}\n",
    "  namespace: {NAMESPACE}\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteMany\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "\"\"\"), text=True, check=True)\n",
    "print(\"PVC ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdcacce3-0f60-4762-b78b-629f4d41ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import component\n",
    "import os\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11-slim\",\n",
    "    packages_to_install=[\"requests\"]\n",
    ")\n",
    "def download_fmnist(pvc_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Fashion MNIST ë°ì´í„°ì…‹ 4ê°œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  PVCì— ì••ì¶• í•´ì œí•©ë‹ˆë‹¤.\n",
    "    ë°˜í™˜ê°’: PVC ë‚´ë¶€ ê²½ë¡œ (ì˜ˆ: \"/mnt/pvc\")\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    import gzip\n",
    "    from io import BytesIO\n",
    "\n",
    "    # ë‹¤ìš´ë¡œë“œí•  4ê°œ íŒŒì¼\n",
    "    urls = [\n",
    "        (\"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\", \"train-images-idx3-ubyte\"),\n",
    "        (\"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\", \"train-labels-idx1-ubyte\"),\n",
    "        (\"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\",  \"t10k-images-idx3-ubyte\"),\n",
    "        (\"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\",  \"t10k-labels-idx1-ubyte\"),\n",
    "    ]\n",
    "\n",
    "    os.makedirs(pvc_path, exist_ok=True)\n",
    "\n",
    "    def download_and_extract(url: str, filename: str):\n",
    "        print(f\"ë‹¤ìš´ë¡œë“œ ì¤‘: {url}\")\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        gz_path = os.path.join(pvc_path, f\"{filename}.gz\")\n",
    "        raw_path = os.path.join(pvc_path, filename)\n",
    "\n",
    "        # .gz ì €ì¥\n",
    "        with open(gz_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # ì••ì¶• í•´ì œ í›„ .gz ì‚­ì œ\n",
    "        with gzip.open(gz_path, \"rb\") as fin, open(raw_path, \"wb\") as fout:\n",
    "            fout.write(fin.read())\n",
    "        os.remove(gz_path)\n",
    "        print(f\"ì™„ë£Œ: {raw_path}\")\n",
    "\n",
    "    for url, name in urls:\n",
    "        download_and_extract(url, name)\n",
    "\n",
    "    print(f\"Fashion MNIST ë°ì´í„°ì…‹ì´ {pvc_path} ì— ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    return pvc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86f4a7fa-db88-489b-b779-370f3da10b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import component\n",
    "import os\n",
    "\n",
    "@component(\n",
    "    base_image=\"pytorch/pytorch:2.3.0-cuda11.8-cudnn8-runtime\",\n",
    "    packages_to_install=[\"torchvision\", \"pillow\", \"numpy\"]\n",
    ")\n",
    "def train_fmnist(\n",
    "    pvc_path: str,\n",
    "    model_name: str,\n",
    "    epochs: int = 3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fashion MNIST í•™ìŠµ + TorchServeìš© handler.py + config.properties ìƒì„±\n",
    "    ë°˜í™˜ê°’: ëª¨ë¸ ë””ë ‰í„°ë¦¬ ê²½ë¡œ (ì˜ˆ: \"/mnt/pvc/fmnist_model\")\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import torchvision.transforms as T\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # ------------------- 1. Dataset -------------------\n",
    "    class FashionMNISTRaw(Dataset):\n",
    "        def __init__(self, img_path, lbl_path, transform=None):\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                data = f.read()\n",
    "                self.images = np.frombuffer(data, np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "            with open(lbl_path, \"rb\") as f:\n",
    "                data = f.read()\n",
    "                self.labels = np.frombuffer(data, np.uint8, offset=8)\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img = self.images[idx].astype(np.float32)\n",
    "            img = torch.from_numpy(img).unsqueeze(0) / 255.0   # (1,28,28)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return img, label\n",
    "\n",
    "    transform = T.Compose([T.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    train_dataset = FashionMNISTRaw(\n",
    "        f\"{pvc_path}/train-images-idx3-ubyte\",\n",
    "        f\"{pvc_path}/train-labels-idx1-ubyte\",\n",
    "        transform=transform\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    # ------------------- 2. Model -------------------\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "            self.pool  = nn.MaxPool2d(2, 2)\n",
    "            self.fc1   = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 7 * 7)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # ------------------- 3. Training -------------------\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs} | Batch {i} | Loss: {running_loss/100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"Training ì™„ë£Œ!\")\n",
    "\n",
    "    # ------------------- 4. Save model -------------------\n",
    "    model_dir = f\"{pvc_path}/fmnist_model\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"{model_dir}/fmnist_cnn.pth\")\n",
    "    print(f\"ëª¨ë¸ ì €ì¥: {model_dir}/fmnist_cnn.pth\")\n",
    "\n",
    "    # ------------------- 5. handler.py -------------------\n",
    "    handler_code = \"\"\"\\\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ImageClassifierHandler(BaseHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        image = data[0].get(\"data\") or data[0].get(\"body\")\n",
    "        if isinstance(image, str):\n",
    "            image = base64.b64decode(image)\n",
    "        image = Image.open(io.BytesIO(image))\n",
    "        return self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        return predicted\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        return [int(inference_output[0])]\n",
    "\"\"\"\n",
    "    Path(f\"{model_dir}/handler.py\").write_text(handler_code)\n",
    "    print(\"handler.py ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    # ------------------- 6. config.properties -------------------\n",
    "    # f-string ì•ˆì— { } ê°€ ë“¤ì–´ê°€ë©´ {{ }} ë¡œ ì´ìŠ¤ì¼€ì´í”„\n",
    "    import json\n",
    "\n",
    "    snapshot = {\n",
    "        \"name\": \"startup.cfg\",\n",
    "        \"modelCount\": 1,\n",
    "        \"models\": {\n",
    "            model_name: {\n",
    "                \"1.0\": {\n",
    "                    \"defaultVersion\": True,\n",
    "                    \"marName\": f\"{model_name}.mar\",\n",
    "                    \"minWorkers\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_content = (\n",
    "        \"inference_address=http://0.0.0.0:8085\\n\"\n",
    "        \"management_address=http://0.0.0.0:8085\\n\"\n",
    "        \"metrics_address=http://0.0.0.0:8082\\n\"\n",
    "        \"model_store=/mnt/pvc/fmnist_model/model-store\\n\"\n",
    "        f\"model_snapshot={json.dumps(snapshot)}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "    config_dir = f\"{model_dir}/config\"\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    Path(f\"{config_dir}/config.properties\").write_text(config_content)\n",
    "    print(\"config.properties ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fa92db6-b72b-46ef-b111-c881fba03ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import component\n",
    "\n",
    "@component(\n",
    "    base_image=\"pytorch/pytorch:2.3.0-cuda11.8-cudnn8-runtime\",\n",
    "    packages_to_install=[\"torch-model-archiver\", \"torchserve\"]\n",
    ")\n",
    "def create_mar(model_dir: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    TorchServeìš© .mar íŒŒì¼ ìƒì„± ì»´í¬ë„ŒíŠ¸\n",
    "    - model_dir: handler.py, *.pth, config.propertiesê°€ í¬í•¨ëœ í´ë”\n",
    "    - ë°˜í™˜ê°’: ìƒì„±ëœ .mar íŒŒì¼ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    model_store = os.path.join(model_dir, \"model-store\")\n",
    "    os.makedirs(model_store, exist_ok=True)\n",
    "\n",
    "    cmd = [\n",
    "        \"torch-model-archiver\",\n",
    "        \"--model-name\", model_name,\n",
    "        \"--version\", \"1.0\",\n",
    "        \"--serialized-file\", f\"{model_dir}/fmnist_cnn.pth\",\n",
    "        \"--handler\", f\"{model_dir}/handler.py\",\n",
    "        \"--export-path\", model_store,\n",
    "        \"--force\"\n",
    "    ]\n",
    "\n",
    "    print(\"ì‹¤í–‰ ì¤‘:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    mar_path = f\"{model_store}/{model_name}.mar\"\n",
    "    print(\"ìƒì„±ëœ MAR íŒŒì¼:\", mar_path)\n",
    "    return mar_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc673050-f792-40cd-ab5d-e61b4a50cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import component, OutputPath\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11-slim\",\n",
    "    packages_to_install=[\"kubernetes\", \"pyyaml\"]\n",
    ")\n",
    "def deploy_kserve(\n",
    "    namespace: str,\n",
    "    isvc_name: str,\n",
    "    model_dir: str,\n",
    "    pvc_name: str,\n",
    "    isvc_yaml_out: OutputPath(str),\n",
    "    isvc_url_out: OutputPath(str)\n",
    "):\n",
    "    \"\"\"\n",
    "    PVCì— ì €ì¥ëœ PyTorch/TorchServe ëª¨ë¸ì„ KServeë¡œ ë°°í¬í•˜ëŠ” ì»´í¬ë„ŒíŠ¸.\n",
    "    \"\"\"\n",
    "    import time, yaml\n",
    "    from kubernetes import client, config\n",
    "\n",
    "    # 1) K8s ì—°ê²°\n",
    "    try:\n",
    "        config.load_incluster_config()\n",
    "    except:\n",
    "        config.load_kube_config()\n",
    "\n",
    "    crd = client.CustomObjectsApi()\n",
    "\n",
    "    # 2) PVCë¥¼ modelUrië¡œ ì‚¬ìš©í•˜ëŠ” predictor\n",
    "    isvc_body = {\n",
    "        \"apiVersion\": \"serving.kserve.io/v1beta1\",\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\n",
    "            \"name\": isvc_name,\n",
    "            \"namespace\": namespace,\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"predictor\": {\n",
    "                \"model\": {\n",
    "                    \"modelFormat\": { \"name\": \"pytorch\" },\n",
    "                    \"storageUri\": f\"pvc://{pvc_name}{model_dir}\",\n",
    "                    \"resources\": {\n",
    "                        \"requests\": {\"cpu\": \"200m\", \"memory\": \"1Gi\"},\n",
    "                        \"limits\":   {\"cpu\": \"1\",    \"memory\": \"2Gi\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 3) ë§Œë“¤ê±°ë‚˜ íŒ¨ì¹˜\n",
    "    group = \"serving.kserve.io\"\n",
    "    version = \"v1beta1\"\n",
    "    plural = \"inferenceservices\"\n",
    "\n",
    "    try:\n",
    "        crd.create_namespaced_custom_object(group, version, namespace, plural, isvc_body)\n",
    "        print(\"InferenceService ìƒì„± ì™„ë£Œ\")\n",
    "    except client.ApiException as e:\n",
    "        if e.status == 409:\n",
    "            crd.patch_namespaced_custom_object(group, version, namespace, plural, isvc_name, isvc_body)\n",
    "            print(\"ê¸°ì¡´ InferenceService íŒ¨ì¹˜ ì™„ë£Œ\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # 4) Ready ëŒ€ê¸°\n",
    "    url = None\n",
    "    for _ in range(60):\n",
    "        obj = crd.get_namespaced_custom_object(group, version, namespace, plural, isvc_name)\n",
    "        status = obj.get(\"status\", {})\n",
    "        address = status.get(\"address\", {})\n",
    "        url = address.get(\"url\")\n",
    "        if url:\n",
    "            break\n",
    "        time.sleep(3)\n",
    "\n",
    "    # 5) ì¶œë ¥ ì €ì¥\n",
    "    with open(isvc_yaml_out, \"w\") as f:\n",
    "        yaml.safe_dump(isvc_body, f)\n",
    "    with open(isvc_url_out, \"w\") as f:\n",
    "        f.write(url or \"\")\n",
    "\n",
    "    print(\"ë°°í¬ ì™„ë£Œ. URL =\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4de52b4-5d12-4458-9c81-ac08a9a07721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp import kubernetes as k8s\n",
    "\n",
    "PVC_NAME   = \"cpu-notebook-workspace\"\n",
    "NAMESPACE  = \"kbm-u-kubeflow-tutorial\"\n",
    "MODEL_NAME = \"fmnist\"\n",
    "ISVC_NAME  = \"fmnist-pytorch\"\n",
    "EPOCHS     = 3\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"FashionMNIST â†’ TorchServe â†’ KServe\",\n",
    "    description=\"PVCì— FMNISTë¥¼ í•™ìŠµí•˜ê³ , ê°™ì€ PVCì—ì„œ KServeë¡œ ë°°í¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸\"\n",
    ")\n",
    "def fmnist_pipeline(\n",
    "    pvc_name: str = PVC_NAME,\n",
    "    model_name: str = MODEL_NAME,\n",
    "    isvc_name: str = ISVC_NAME,\n",
    "    namespace: str = NAMESPACE,\n",
    "    epochs: int = EPOCHS,\n",
    "):\n",
    "    # 1) ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "    dl = download_fmnist(pvc_path=\"/mnt/pvc\")\n",
    "    k8s.mount_pvc(dl, pvc_name=pvc_name, mount_path=\"/mnt/pvc\")\n",
    "\n",
    "    # 2) í•™ìŠµ (ë‹¤ìš´ë¡œë“œ ì´í›„ ì‹¤í–‰ + GPU)\n",
    "    train = train_fmnist(\n",
    "        pvc_path=\"/mnt/pvc\",\n",
    "        model_name=model_name,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    k8s.mount_pvc(train, pvc_name=pvc_name, mount_path=\"/mnt/pvc\")\n",
    "    train.add_node_selector_constraint(\"nvidia.com/gpu.present=true\")\n",
    "    train.set_gpu_limit(1)\n",
    "    train.after(dl)  # ğŸ”´ ë°˜ë“œì‹œ ë‹¤ìš´ë¡œë“œ ì´í›„ì— í•™ìŠµ ì‹œì‘\n",
    "\n",
    "    # 3) KServe ë°°í¬ (í•™ìŠµ ì´í›„ ì‹¤í–‰)\n",
    "    # train_fmnistê°€ /mnt/pvc/fmnist_model ì— ì €ì¥í•œë‹¤ê³  ê°€ì •í•˜ë©´\n",
    "    # PVC ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œëŠ” /fmnist_model\n",
    "    deploy = deploy_kserve(\n",
    "        namespace=namespace,\n",
    "        isvc_name=isvc_name,\n",
    "        model_dir=\"/fmnist_model\",\n",
    "        pvc_name=pvc_name,\n",
    "    )\n",
    "    deploy.after(train)  # ğŸ”´ í•™ìŠµì´ ëë‚œ ë’¤ ë°°í¬ ì‹¤í–‰\n",
    "\n",
    "    # ìºì‹± ë„ê¸° (ì„ íƒ)\n",
    "    for t in [dl, train, deploy]:\n",
    "        t.set_caching_options(enable_caching=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad8c8cb2-1c16-475f-ba7c-0b2cede6bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] fmnist-kserve-pipeline.yaml created\n"
     ]
    }
   ],
   "source": [
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=fmnist_pipeline,\n",
    "    package_path=\"fmnist-kserve-pipeline.yaml\",\n",
    ")\n",
    "\n",
    "print(\"[Done] fmnist-kserve-pipeline.yaml created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b227cc8-9840-4c92-8fed-cb50f689466a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
